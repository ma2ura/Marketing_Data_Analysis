[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "マーケティング・データ分析の学習メモ",
    "section": "",
    "text": "0.1 はじめに\nこのノートは、神戸大学の田頭拓己先生が書かれた「マーケティング・データ分析」に関する学習内容をまとめたものです。 統計学の基礎を学習し，その知識を使ってマーケティングについて各自が持っている問題意識や，抱えている課題について深く理解し，解決するための糸口を見つける力を養う，という点で非常に優れたテキストです。",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>はじめに</span>"
    ]
  },
  {
    "objectID": "index.html#準備",
    "href": "index.html#準備",
    "title": "マーケティング・データ分析の学習メモ",
    "section": "0.2 準備",
    "text": "0.2 準備\n各自のPC(WindowsかMacを想定)の好きな場所にMarketing_data_analysisというフォルダを作成し，そこを作業ディレクトリにしていることを想定しています。この文章の意味が分からない人は，Rの入門書を確認してください。 作業ディレクトリの中にdataというフォルダを作成し，そこにテキストで使うデータファイルを保存してある，という前提で進めます。",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>はじめに</span>"
    ]
  },
  {
    "objectID": "part01.html",
    "href": "part01.html",
    "title": "第1部",
    "section": "",
    "text": "第1章 RとRstudioに慣れる\nRとRを便利に使うための統合環境であるRstudioの基本的な使い方を学びます。R初学者はしっかり読んで準備しておいてください。 ただ、この章の内容は，数多く出版されているRの解説書で代替できるため，割愛します。\nまた，この本ではコードを書く環境としてRstudioを想定していますが，個人的にはMicrosoft社が開発しているVisual Studio Code (VSCode)やPosit社が開発しているPositronを推奨しているので，この章の内容には触れません。",
    "crumbs": [
      "第1部"
    ]
  },
  {
    "objectID": "part01.html#第2章-リサーチデザインと問いの設計",
    "href": "part01.html#第2章-リサーチデザインと問いの設計",
    "title": "第1部",
    "section": "第2章 リサーチ・デザインと問いの設計",
    "text": "第2章 リサーチ・デザインと問いの設計\n経営学部生がビジネスに関する問いを立てる際に重要なポイントを解説しています。\n必読です。\nただRのコードは出てこないので、ここでは解説しません。各自で熟読しておきましょう。",
    "crumbs": [
      "第1部"
    ]
  },
  {
    "objectID": "part01.html#第3章-尺度と質問紙調査設計",
    "href": "part01.html#第3章-尺度と質問紙調査設計",
    "title": "第1部",
    "section": "第3章 尺度と質問紙調査設計",
    "text": "第3章 尺度と質問紙調査設計\nマーケティング研究でよく利用されている質問紙を使ったアンケート調査の設計方法について解説しています。 いろんなところで利用されているアンケートですが、設計段階でいろんな人の思いが錯綜し、本来知りたかった事を調査できていないことが多々あります。\n第4章は「データ整理と要約」というテーマで、Rを使ってデータの整理や要約を行う方法について解説しています。データ分析の前にデータを適切に整理し、要約することは非常に重要です。この章では、Rの基本的なデータ操作や要約統計量の計算方法について学びます。",
    "crumbs": [
      "第1部"
    ]
  },
  {
    "objectID": "chapter04.html",
    "href": "chapter04.html",
    "title": "2  データ整理と要約",
    "section": "",
    "text": "2.0.1 dplyrでデータの要約\n第4章は、データを読み込んで、形を整えて、特徴をつかむためのデータを要約する方法を学びます。 Rは最初から用意されている基本関数だけでも十分強力ですが、外部で開発された様々なパッケージを使うと、さらに便利にデータ操作ができます。\nはじめに外部のパッケージをインストールしてRの機能を拡張します。 Rでデータを操作する際に超強力なパッケージ群であるtidyverseを読み込みます。 あとで使うExcelファイルを読み込むためのreadxlパッケージも一緒に読み込みます。\nテキストでは、install.packages()関数でパッケージをインストールして、library()関数で読み込んでいますが、ここではpacman`パッケージを使って、必要なパッケージを一括でインストールおよび読み込みをします。\nまず始めに、pacmanパッケージをインストールします。 この作業はここで1回だけです。以降はこのコードは実行しなくて大丈夫です。\n次に、pacmanパッケージのp_load()関数を使って，tidyverseとreadxlパッケージをインストールおよび読み込みします。 ::という記法はパッケージ名を明示的に指定して関数を使う方法ですが、ここではpacmanパッケージのp_load()関数を指定して使っています。\n作業ディレクトリ内のdataフォルダに入っている2022idpos.csvというデータを読み込みます。 何を読み込んだのか確認するために，基本関数head()でデータの先頭6行を表示させます。\n読み込んだデータに含まれている変数の名前を確認するため，基本関数names()を使います。\nデータの詳細を確認するため，tidyverseのdplyrパッケージのglimpse()関数を使います。\nExcelのようにデータを表示させたいなら，基本関数View()を使います。\nこれで，自分が読み込んだデータがどんなものかを確認できました。\ntidyverseのdplyrパッケージを使うと，データの要約が簡単にできます。 ここでは，\nの使い方を学びます。\n先ほど読み込んだデータには，\nという4変数に3,000の観測値が含まれています。 このデータをdplyrの各関数を使って，以下のような操作をしてみます。\nまず，\nという一連の操作を行います(この処理に意味はないです。)\n# コード4-11（見本コード）\nidpos |&gt;\n  select(spent, coupon) |&gt;\n  arrange(desc(spent)) |&gt;\n  mutate(spent10 = spent * 10) |&gt;\n  filter(spent10 &gt;= 10000) |&gt;\n  summarise(mean_spent10 = mean(spent10)) |&gt;\n  rename(spent_times10 = mean_spent10)\nすると，spentを10倍して，1万円以上の買い物の平均値を計算した結果がspent_times10として表示されます。\nこのように加工したデータをcsvファイルとして保存するには、readrパッケージのwrite_csv()関数を使います。 write_csv()関数は、第1引数に保存したいデータフレームを指定し、第2引数に保存先のファイルパスを指定します。\nreadr::write_csv(idpos, path = \"data/new_data.csv\")",
    "crumbs": [
      "第1部",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>データ整理と要約</span>"
    ]
  },
  {
    "objectID": "chapter04.html#データの要約",
    "href": "chapter04.html#データの要約",
    "title": "2  データ整理と要約",
    "section": "2.1 4 データの要約",
    "text": "2.1 4 データの要約\n大規模データをあつかうとき、データそのものを眺めていても特徴をつかむことは難しいので、そのデータを特徴付ける代表値を計算して、そこからデータの特徴をつかみます。 主要な代表値として、平均値(mean)や中央値(median)、散らばり具合を示す分散(variance)や標準偏差(standard deviation)があります。 それぞれ、\n\n平均値：mean()関数\n中央値：median()関数\n分散：var()関数\n標準偏差：sd()関数\n\nを使って計算します。\n先ほどのデータfirm2018_checkのsales変数について、代表値を計算してみます。 ここでは、dplyrパッケージのsummarize()関数を使って、平均、中央値、分散、標準偏差を一度に計算します。\n\nfirm2018_check |&gt; \n  summarize(\n    mean_sales   = mean(sales),\n    median_sales = median(sales),\n    var_sales    = var(sales),\n    sd_sales     = sd(sales)\n  )",
    "crumbs": [
      "第1部",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>データ整理と要約</span>"
    ]
  },
  {
    "objectID": "chapter04.html#カテゴリ変数の要約",
    "href": "chapter04.html#カテゴリ変数の要約",
    "title": "2  データ整理と要約",
    "section": "2.2 カテゴリ変数の要約",
    "text": "2.2 カテゴリ変数の要約\nつぎに、データ上は数値や文字列として記録されていても、その数値や文字列がカテゴリーを表す名義尺度(nominal scale)である場合を考えましょう。\n例えば、firmdataの中の産業分類を表すind_en変数は、文字列で表現されていますが、その文字列はある観測値が所属するカテゴリーを表しています。 fyear変数は数値ですが、これは年度を表すカテゴリー変数です。\nカテゴリ内の観測値の頻度を確認するには基本関数table()を使いますが、ここでは、dplyr::count()関数を使って、ind_en変数の各カテゴリーの頻度を計算し、gtパッケージで表形式で表示します。\n\nfirm2018 &lt;- firmdata |&gt;\n  filter(fyear == 2018) # 2018年のデータを抽出\nfirm2018 |&gt;\n  dplyr::count(ind_en, name = \"企業数\") |&gt;\n  gt::gt() |&gt;\n  gtExtras::gt_theme_538()\n\n\n\n\n\n\n\nind_en\n企業数\n\n\n\n\nAir Transportation\n8\n\n\nAmusement Services\n4\n\n\nBakery Products\n1\n\n\nCommunication Services\n2\n\n\nCosmetics & Toilet Goods\n3\n\n\nDepartment Stores\n7\n\n\nFoods, NEC\n1\n\n\nHome & Pre-Fabs\n2\n\n\nHotels\n5\n\n\nMiscellaneous Services\n27\n\n\nMiscellaneous Wholesales\n2\n\n\nMotor Vehicles\n4\n\n\nMusical Instrument\n1\n\n\nRailroad (Major)\n27\n\n\nRailroad (Minor)\n2\n\n\nReal Estate - Sales\n1\n\n\nRetail Stores, NEC\n35\n\n\nSupermarket Chains\n14\n\n\nTrucking\n1\n\n\n\n\n\n\n\n\n\n教科書のようにtable()関数を使うと簡単に頻度表が作れますが、オブジェクトの型がtable型になってしまい、後で他の処理に使いにくくなるので、data.frame型のまま処理できるdplyr::count()関数を使いました。\n広告費を表すadient変数の観測値が全企業の中央値より大きいか否か、でダミー変数ad_dummyを作成し、ind_en変数とad_dummy変数のクロス集計表を作成します。\n教科書を先取りしますが、if_else()関数を使ってダミー変数を作成し、count()関数でクロス集計表を作成し、gtパッケージで表形式で表示します。 tidyrパッケージのpivot_wider()関数を使って、クロス集計表が見やすくなるように、縦は産業名、横は広告費が中央値より大きいか否か、で表示するように変形しています。\n\n\ntable()関数を使うと簡単にクロス集計表が作れますが、あえてdata.frame型のまま処理できるdplyr::count()関数を使っています。そのため、データが矩形データのまま扱えるので、後で他の処理に使いやすくなるものの、表にすると見にくくなるので、tidyr::pivot_wider()関数で見やすく変形しています。\n\nfirm2018 &lt;- firm2018 |&gt;\n  mutate(\n    ad_dummy = if_else(adint &gt; median(adint, na.rm = TRUE), 1L, 0L)\n    )\nfirm2018 %&gt;%\n  count(ind_en, ad_dummy) |&gt;\n  tidyr::pivot_wider(names_from = ad_dummy, values_from = n, values_fill = 0) |&gt;\n  gt::gt() |&gt;\n  gtExtras::gt_theme_538()\n\n\n\n\n\n\n\nind_en\n0\n1\n\n\n\n\nAir Transportation\n4\n4\n\n\nAmusement Services\n4\n0\n\n\nBakery Products\n0\n1\n\n\nCommunication Services\n1\n1\n\n\nCosmetics & Toilet Goods\n0\n3\n\n\nDepartment Stores\n0\n7\n\n\nFoods, NEC\n0\n1\n\n\nHome & Pre-Fabs\n0\n2\n\n\nHotels\n5\n0\n\n\nMiscellaneous Services\n17\n10\n\n\nMiscellaneous Wholesales\n1\n1\n\n\nMotor Vehicles\n0\n4\n\n\nMusical Instrument\n0\n1\n\n\nRailroad (Major)\n27\n0\n\n\nRailroad (Minor)\n2\n0\n\n\nReal Estate - Sales\n0\n1\n\n\nRetail Stores, NEC\n11\n24\n\n\nSupermarket Chains\n2\n12\n\n\nTrucking\n1\n0\n\n\n\n\n\n\n\n次に、カテゴリ変数ごとに処理を行いたい場合、例えば、産業分類ごとに売上高の平均値や標準偏差を計算したい場合は、group_by()関数を使って、カテゴリ変数でグループ化してから、summarize()関数で集計します。\n\n# コード4-39\nfirm2018 |&gt;\n  group_by(ind_en) |&gt;\n  summarize(\n      obs = n(),\n      sales_m = mean(sales),\n      sales_sd = sd(sales),\n      adint_m = mean(adint),\n      adint_sd = sd(adint)\n      ) |&gt;\n  gt::gt() |&gt;\n  gt::fmt_number(\n    columns = c(sales_m, sales_sd, adint_m, adint_sd),\n    decimals = 2\n  ) |&gt;\n  gtExtras::gt_theme_538()\n\n\n\n\n\n\n\nind_en\nobs\nsales_m\nsales_sd\nadint_m\nadint_sd\n\n\n\n\nAir Transportation\n8\n1,772,786.50\n305,239.60\n0.00\n0.00\n\n\nAmusement Services\n4\n298,137.50\n263,017.35\n0.00\n0.00\n\n\nBakery Products\n1\n1,059,442.00\nNA\n0.01\nNA\n\n\nCommunication Services\n2\n547,087.50\n172,735.58\n0.02\n0.03\n\n\nCosmetics & Toilet Goods\n3\n140,669.33\n100,063.48\n0.11\n0.05\n\n\nDepartment Stores\n7\n843,248.29\n348,818.99\n0.02\n0.01\n\n\nFoods, NEC\n1\n504,153.00\nNA\n0.02\nNA\n\n\nHome & Pre-Fabs\n2\n4,143,505.00\n0.00\n0.01\n0.00\n\n\nHotels\n5\n62,134.80\n58,060.28\n0.00\n0.00\n\n\nMiscellaneous Services\n27\n311,867.22\n456,036.57\n0.01\n0.02\n\n\nMiscellaneous Wholesales\n2\n176,520.00\n52,778.45\n0.02\n0.03\n\n\nMotor Vehicles\n4\n5,279,121.75\n4,233,187.72\n0.03\n0.00\n\n\nMusical Instrument\n1\n434,373.00\nNA\n0.04\nNA\n\n\nRailroad (Major)\n27\n1,302,920.52\n1,037,834.05\n0.00\n0.00\n\n\nRailroad (Minor)\n2\n260,502.00\n0.00\n0.00\n0.00\n\n\nReal Estate - Sales\n1\n1,861,195.00\nNA\n0.01\nNA\n\n\nRetail Stores, NEC\n35\n571,019.17\n547,246.68\n0.02\n0.03\n\n\nSupermarket Chains\n14\n4,335,164.07\n3,511,346.59\n0.01\n0.01\n\n\nTrucking\n1\n1,118,094.00\nNA\n0.00\nNA",
    "crumbs": [
      "第1部",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>データ整理と要約</span>"
    ]
  },
  {
    "objectID": "part02.html",
    "href": "part02.html",
    "title": "第2部 仮説検証型データ分析",
    "section": "",
    "text": "第5章では基本統計学の復習を、第6章では回帰分析、第7章では回帰分析の応用としてダミー変数や交差項、変数変換について学習します。 第8章では消費者選択を分析するための離散選択モデルとして、ロジットモデルとプロビットモデル、多項選択モデルを学びます。",
    "crumbs": [
      "第2部 仮説検証型データ分析"
    ]
  },
  {
    "objectID": "chapter05.html",
    "href": "chapter05.html",
    "title": "3  第5章 基礎統計学復習",
    "section": "",
    "text": "3.1 区間推定\n経営学部の1回生がおおよそ学んでいるであろう統計学の内容を、Rコードとともに復習します。 テキストの内容に加えて、コードの効率化や関数化についても解説します。\nまずサイコロを作ります。 1から6の数値からなるベクトルdiceを作ります。 つぎにsample()関数を用いて、diceの中から1つの数をランダムに取り出します。\n同じコードを3回以上書いているなと思ったら、ループ処理や関数化を検討しましょう。 for()関数を使ったり、サイコロを投げる回数を引数にした関数を作成したりする方法があります。\nをまとめて書くと、次のようになります。\nこれをさらに発展させて、後で変更する可能性のある変数である試行回数やサイコロを振る回数を別に設定しておいて、コードを読みやすく、また変更しやすくします。\n試行回数trialsとサイコロを振る回数sample_sizesを引数にした関数を作成すると、さらに便利になります。 ここでは、自作関数dice_mean()を定義してみましょう。 デフォルト値として、試行回数を3回、サイコロを振る回数を10回に設定しています。\nこの関数を使って、サイコロを10回、100回、1,000回振ったときの平均をそれぞれ3回ずつ試行してみましょう。\ntidyverseのpurrrパッケージを使うと、さらに簡潔に書けます。\nいま、標準正規分布に従う母集団から抽出した無作為標本Z_1, Z_2, ..., Z_nを考えます。 標準正規分布の確率分布関数\\phi(z)を用いると、次のように表せます。 \nP \\left( -z_{\\frac{\\alpha}{2}} \\leq \\frac{\\bar{Z} - \\mu}{\\frac{\\sigma}{\\sqrt{n}}} \\leq z_{\\frac{\\alpha}{2}} \\right) = 1 - \\alpha",
    "crumbs": [
      "第2部 仮説検証型データ分析",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>第5章 基礎統計学復習</span>"
    ]
  },
  {
    "objectID": "chapter06.html",
    "href": "chapter06.html",
    "title": "4  第6章",
    "section": "",
    "text": "pacman::p_load(tidyverse, readxl, GGally, knitr)\n\n# コード6-1\nfirmdata &lt;- readxl::read_xlsx(\"data/MktRes_firmdata.xlsx\")\n\n# コード6-2\nlibrary(tidyverse)\nfirmdata19 &lt;- firmdata %&gt;%\n  filter(fyear == 2019)\n\n# コード6-3\n# install.packages(\"GGally\")\n\n# コード6-4\nfirmdata19 %&gt;%\n  select(sales, mkexp, emp, operating_profit) %&gt;%\n  GGally::ggpairs() + labs(title = \"ggpairs example\")\n\n\n\n\n\n\n\n# コード6-5\nds1 &lt;- firmdata19 %&gt;%\n  select(sales, mkexp, emp, operating_profit) %&gt;%\n  summary()\nknitr::kable(ds1, align = \"cccc\")\n\n\n\n\n\n\n\n\n\n\n\n\nsales\nmkexp\nemp\noperating_profit\n\n\n\n\n\nMin. : 11333\nMin. :0.01137\nMin. : 163\nMin. :-40469\n\n\n\n1st Qu.: 183525\n1st Qu.:0.16714\n1st Qu.: 3454\n1st Qu.: 7743\n\n\n\nMedian : 464450\nMedian :0.25448\nMedian : 7826\nMedian : 23904\n\n\n\nMean :1199403\nMean :0.29868\nMean : 20249\nMean : 81088\n\n\n\n3rd Qu.:1164243\n3rd Qu.:0.37506\n3rd Qu.: 24464\n3rd Qu.: 63068\n\n\n\nMax. :9878866\nMax. :0.75650\nMax. :160227\nMax. :656163\n\n\n\n\n# コード6-6\nreg1 &lt;- lm(sales ~ emp, data = firmdata19)\ncoef(reg1)\n\n(Intercept)         emp \n22113.98050    58.14081 \n\n# コード6-7\nsummary(reg1)\n\n\nCall:\nlm(formula = sales ~ emp, data = firmdata19)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-1834902  -280228   -34549   136598  3292521 \n\nCoefficients:\n             Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) 22113.980  89224.761   0.248    0.805    \nemp            58.141      2.569  22.628   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 875800 on 144 degrees of freedom\nMultiple R-squared:  0.7805,    Adjusted R-squared:  0.779 \nF-statistic:   512 on 1 and 144 DF,  p-value: &lt; 2.2e-16\n\n# コード6-8\nconfint(reg1, level = 0.99)\n\n                    0.5 %       99.5 %\n(Intercept) -210798.52845 255026.48944\nemp              51.43362     64.84799\n\n# コード6-9\nreg2 &lt;- lm(operating_profit ~ adv, data = firmdata19)\nsummary(reg2)\n\n\nCall:\nlm(formula = operating_profit ~ adv, data = firmdata19)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-450526  -55552  -40672    -791  599084 \n\nCoefficients:\n             Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) 5.708e+04  1.057e+04   5.401 2.68e-07 ***\nadv         1.257e+00  2.159e-01   5.823 3.61e-08 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 117600 on 144 degrees of freedom\nMultiple R-squared:  0.1906,    Adjusted R-squared:  0.185 \nF-statistic: 33.91 on 1 and 144 DF,  p-value: 3.613e-08\n\n# コード6-10\nconfint(reg2)\n\n                   2.5 %       97.5 %\n(Intercept) 36189.311039 77968.894422\nadv             0.830362     1.683719\n\n# コード6-11\nreg3 &lt;- lm(operating_profit ~ adv + temp + emp + labor_cost\n           + total_assets + rd, data = firmdata19)\nsummary(reg3)\n\n\nCall:\nlm(formula = operating_profit ~ adv + temp + emp + labor_cost + \n    total_assets + rd, data = firmdata19)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-360544  -27618  -15279    3467  284094 \n\nCoefficients:\n               Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)   2.209e+04  8.114e+03   2.723  0.00731 ** \nadv          -1.431e+00  2.954e-01  -4.845 3.34e-06 ***\ntemp         -1.878e+00  6.313e-01  -2.975  0.00346 ** \nemp          -1.510e+00  7.036e-01  -2.146  0.03358 *  \nlabor_cost    8.808e-01  1.692e-01   5.207 6.76e-07 ***\ntotal_assets  3.516e-02  5.840e-03   6.020 1.47e-08 ***\nrd            1.385e+00  5.268e-01   2.629  0.00953 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 78940 on 139 degrees of freedom\nMultiple R-squared:  0.6479,    Adjusted R-squared:  0.6327 \nF-statistic: 42.63 on 6 and 139 DF,  p-value: &lt; 2.2e-16\n\n# コード6-12\nconfint(reg3)\n\n                     2.5 %        97.5 %\n(Intercept)  6048.51599480  3.813231e+04\nadv            -2.01511513 -8.470054e-01\ntemp           -3.12602311 -6.298318e-01\nemp            -2.90144939 -1.190356e-01\nlabor_cost      0.54637427  1.215313e+00\ntotal_assets    0.02361376  4.670793e-02\nrd              0.34334525  2.426472e+00",
    "crumbs": [
      "第2部 仮説検証型データ分析",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>第6章</span>"
    ]
  },
  {
    "objectID": "chapter07.html",
    "href": "chapter07.html",
    "title": "\n5  第7章\n",
    "section": "",
    "text": "pacman::p_load(tidyverse, readxl, sjPlot, marginaleffects, car, modelsummary)\n# コード7-1\n# library(tidyverse)\nfirmdata &lt;- readxl::read_xlsx(\"data/MktRes_firmdata.xlsx\")\nfirmdata19 &lt;- firmdata %&gt;%\n  filter(fyear == 2019)\n#産業名を特定したオブジェクト\"Retail\"の作成\nretail &lt;- c(\"Retail Stores, NEC\", \"Supermarket Chains\",\n            \"Department Stores\")\n# Retail を使ったカテゴリー変数の作成\nfirmdata19 &lt;- firmdata19 %&gt;%\n  mutate(format = ifelse(ind_en %in% retail, \"Retail\", \"Other\"))\n#カテゴリーの頻度チェック\nwith(firmdata19, table(format))\n\nformat\n Other Retail \n    90     56 \n\n# コード7-2\nfit.d1 &lt;- lm(op ~ mkexp + format, data = firmdata19)\nsummary(fit.d1)\n\n\nCall:\nlm(formula = op ~ mkexp + format, data = firmdata19)\n\nResiduals:\n      Min        1Q    Median        3Q       Max \n-0.095926 -0.031427 -0.008661  0.014345  0.261068 \n\nCoefficients:\n              Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)   0.101694   0.008833  11.514  &lt; 2e-16 ***\nmkexp        -0.066003   0.024959  -2.644 0.009097 ** \nformatRetail -0.031770   0.009303  -3.415 0.000831 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.05368 on 143 degrees of freedom\nMultiple R-squared:  0.1379,    Adjusted R-squared:  0.1258 \nF-statistic: 11.44 on 2 and 143 DF,  p-value: 2.469e-05\n\n# コード7-3\nfirmdata19 &lt;- firmdata19 %&gt;%\n  mutate(retail = ifelse(format == \"Retail\", 1, 0))\n\n# 確認\nwith(firmdata19, table(retail, format))\n\n      format\nretail Other Retail\n     0    90      0\n     1     0     56\n\n# コード7-4\nfit.d2 &lt;- lm(op ~ mkexp + retail, data = firmdata19)\nsummary(fit.d2)\n\n\nCall:\nlm(formula = op ~ mkexp + retail, data = firmdata19)\n\nResiduals:\n      Min        1Q    Median        3Q       Max \n-0.095926 -0.031427 -0.008661  0.014345  0.261068 \n\nCoefficients:\n             Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  0.101694   0.008833  11.514  &lt; 2e-16 ***\nmkexp       -0.066003   0.024959  -2.644 0.009097 ** \nretail      -0.031770   0.009303  -3.415 0.000831 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.05368 on 143 degrees of freedom\nMultiple R-squared:  0.1379,    Adjusted R-squared:  0.1258 \nF-statistic: 11.44 on 2 and 143 DF,  p-value: 2.469e-05\n\n# コード7-5\nfit.d3 &lt;- lm(op ~ mkexp * retail, data = firmdata19)\nsummary(fit.d3)\n\n\nCall:\nlm(formula = op ~ mkexp * retail, data = firmdata19)\n\nResiduals:\n      Min        1Q    Median        3Q       Max \n-0.100914 -0.027907 -0.006023  0.020847  0.254339 \n\nCoefficients:\n              Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)   0.112780   0.009123  12.362  &lt; 2e-16 ***\nmkexp        -0.106801   0.026898  -3.971 0.000113 ***\nretail       -0.099242   0.021752  -4.563 1.08e-05 ***\nmkexp:retail  0.205666   0.060393   3.405 0.000859 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.0518 on 142 degrees of freedom\nMultiple R-squared:  0.203, Adjusted R-squared:  0.1862 \nF-statistic: 12.06 on 3 and 142 DF,  p-value: 4.461e-07\n\n# コード7-6\n# install.packages(\"sjPlot\")\n\n# コード7-7\n# # library(sjPlot)\npred &lt;- plot_model(fit.d3,\n  type = \"pred\",\n  terms = c(\"mkexp\", \"retail\"),\n  ci.lvl = .95) +\n  labs(\n    title = \"Slope Analysis\",\n    subtitle = \"(Predicted Values of Profitability with 95% Confidence Intervals)\",\n    x = \"Marketing Expense\",\n    y = \"Profitability\"\n  ) + scale_color_discrete(name = \"Retail Dummy\")\npred\n\n\n\n\n\n\n# コード7-8\nHeadphone07 &lt;- readr::read_csv(\"data/headphone07.csv\", na = \".\")\n\n#データフレームの確認\nglimpse(Headphone07)\n\nRows: 221\nColumns: 4\n$ ID        &lt;dbl&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 1…\n$ sales     &lt;dbl&gt; 118.8377, 548.6312, 197.3075, 104.2657, 748.8251, 947.8850, …\n$ rd        &lt;dbl&gt; 404.0893, 252.1270, 444.3374, 407.5876, 841.7605, 336.8744, …\n$ promotion &lt;dbl&gt; 75.63163, 102.74572, 97.98040, 83.46613, 105.69250, 80.17476…\n\n# コード7-9\nfit_int &lt;- lm(sales ~ rd * promotion, data = Headphone07)\nsummary(fit_int)\n\n\nCall:\nlm(formula = sales ~ rd * promotion, data = Headphone07)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-46.522 -12.861  -0.638  13.578  70.667 \n\nCoefficients:\n               Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)   2.033e+04  1.090e+02   186.5   &lt;2e-16 ***\nrd           -5.187e+01  2.844e-01  -182.4   &lt;2e-16 ***\npromotion    -1.914e+02  1.052e+00  -181.9   &lt;2e-16 ***\nrd:promotion  4.979e-01  2.730e-03   182.4   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 20.55 on 217 degrees of freedom\nMultiple R-squared:  0.9935,    Adjusted R-squared:  0.9934 \nF-statistic: 1.111e+04 on 3 and 217 DF,  p-value: &lt; 2.2e-16\n\n# コード7-10\nHeadphone07 &lt;- Headphone07 %&gt;%\n  mutate(promotion_c = promotion - mean(promotion, na.rm = TRUE),\n         rd_c = rd - mean(rd, na.rm = TRUE))\n\nfit_int_c &lt;- lm(sales ~ rd_c * promotion_c , data = Headphone07)\nsummary(fit_int_c)\n\n\nCall:\nlm(formula = sales ~ rd_c * promotion_c, data = Headphone07)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-46.522 -12.861  -0.638  13.578  70.667 \n\nCoefficients:\n                  Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)      382.27812    1.51459  252.40   &lt;2e-16 ***\nrd_c              -0.91767    0.01196  -76.75   &lt;2e-16 ***\npromotion_c        0.69039    0.03972   17.38   &lt;2e-16 ***\nrd_c:promotion_c   0.49792    0.00273  182.37   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 20.55 on 217 degrees of freedom\nMultiple R-squared:  0.9935,    Adjusted R-squared:  0.9934 \nF-statistic: 1.111e+04 on 3 and 217 DF,  p-value: &lt; 2.2e-16\n\n# コード7-11\nleg = c(\"Mean - 1sd\", \"Mean\", \"Mean + 1sd\")\nint_fig1 &lt;- plot_model(fit_int_c,\n type = \"int\",\n mdrt.values = \"meansd\",\n ci.lvl = .9999999999) +\n  labs(\n    title = \"Predicted values of Sales(R&D * Promotion)\",\n    x = \"R&D Investment\",\n    y = \"Sales\") +\n  scale_color_discrete(\n    name = \"Promotion level\",\n    labels = leg)\nint_fig1\n\n\n\n\n\n\n# コード7-12\n# install.packages(\"marginaleffects\")\n\n# コード7-13\n# library(marginaleffects)\nint_fig2 &lt;- plot_slopes(fit_int_c, variables = \"rd_c\",\n  condition = \"promotion_c\", conf_level = .99999999) +\n  labs(title = \"Marginal effects of R&D on Sales\",\n       x = \"Promotion\", y = \"Slope of R&D on Sales\") +\n  geom_hline(aes(yintercept = 0), linetype = \"dashed\")\nint_fig2\n\n\n\n\n\n\n# コード7-14\nfirmdata19 &lt;- firmdata19 %&gt;%\n  mutate(mkexp_c = mkexp - mean(mkexp),\n         asset_c = total_assets - mean(total_assets))\nfit_int2 &lt;- lm(op ~ mkexp_c * asset_c, data = firmdata19)\nint_fig3 &lt;- plot_slopes(fit_int2, variables = \"mkexp_c\",\n  condition = \"asset_c\", conf_level = 0.99) +\n  geom_hline(aes(yintercept = 0), linetype = \"dashed\")\nint_fig3\n\n\n\n\n\n\n# コード7-15\nfirmdata19 &lt;- firmdata19 %&gt;%\n  mutate(adv = (adv - mean(adv)) / sd(adv),\n         rd = (rd - mean(rd)) / sd(rd),\n         ad_rd = adv + rd)\nfit_linear &lt;- lm(sales ~ adv + rd, data = firmdata19)\nsummary(fit_linear) \n\n\nCall:\nlm(formula = sales ~ adv + rd, data = firmdata19)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-4357995  -463348  -236824   123663  2692251 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  1199403      74285  16.146   &lt;2e-16 ***\nadv          1632326      74996  21.766   &lt;2e-16 ***\nrd             29915      74996   0.399    0.691    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 897600 on 143 degrees of freedom\nMultiple R-squared:  0.7711,    Adjusted R-squared:  0.7679 \nF-statistic: 240.8 on 2 and 143 DF,  p-value: &lt; 2.2e-16\n\n# コード7-16\nfit_comp &lt;- lm(sales ~ adv + ad_rd, data = firmdata19)\nsummary(fit_comp)\n\n\nCall:\nlm(formula = sales ~ adv + ad_rd, data = firmdata19)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-4357995  -463348  -236824   123663  2692251 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  1199403      74285  16.146   &lt;2e-16 ***\nadv          1602411     111739  14.341   &lt;2e-16 ***\nad_rd          29915      74996   0.399    0.691    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 897600 on 143 degrees of freedom\nMultiple R-squared:  0.7711,    Adjusted R-squared:  0.7679 \nF-statistic: 240.8 on 2 and 143 DF,  p-value: &lt; 2.2e-16\n\n# コード7-17\nfit_prod &lt;- lm(log(sales) ~ log(labor_cost) + log(ppent),\n  data = firmdata19)\n\nsummary(fit_prod) \n\n\nCall:\nlm(formula = log(sales) ~ log(labor_cost) + log(ppent), data = firmdata19)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-1.40821 -0.36129 -0.00933  0.38591  1.66673 \n\nCoefficients:\n                Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)      3.17129    0.31733   9.994   &lt;2e-16 ***\nlog(labor_cost)  0.53739    0.03679  14.605   &lt;2e-16 ***\nlog(ppent)       0.34588    0.02797  12.366   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.5169 on 143 degrees of freedom\nMultiple R-squared:  0.8747,    Adjusted R-squared:  0.8729 \nF-statistic: 499.1 on 2 and 143 DF,  p-value: &lt; 2.2e-16\n\n# コード7-18\nprice &lt;- readr::read_csv(\"data/price_data.csv\")\n\nfit_q &lt;- lm(log(q) ~ log(p), data = price)\nsummary(fit_q) \n\n\nCall:\nlm(formula = log(q) ~ log(p), data = price)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-1.11220 -0.13668  0.02804  0.16166  0.51039 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  9.47781    0.08135   116.5   &lt;2e-16 ***\nlog(p)      -0.18008    0.01354   -13.3   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.2309 on 998 degrees of freedom\nMultiple R-squared:  0.1506,    Adjusted R-squared:  0.1497 \nF-statistic: 176.9 on 1 and 998 DF,  p-value: &lt; 2.2e-16\n\n# コード7-19\n# install.packages(\"car\")\n\n# コード7-20\n# library(car)\nlinearHypothesis(fit_q, c(\"log(p)= -1\"))\n\n\n  \n\n\n# コード7-21\n# install.packages(\"modelsummary\")\n\n# コード7-22\n# library(modelsummary)\nmsummary(fit_int, statistic = 'conf.int')\n\n\n\n    \n\n      \n\n \n                (1)\n              \n\n\n(Intercept)\n                  20326.588\n                \n\n\n                  [20111.797, 20541.378]\n                \n\nrd\n                  -51.872\n                \n\n\n                  [-52.433, -51.312]\n                \n\npromotion\n                  -191.431\n                \n\n\n                  [-193.505, -189.358]\n                \n\nrd × promotion\n                  0.498\n                \n\n\n                  [0.493, 0.503]\n                \n\nNum.Obs.\n                  221\n                \n\nR2\n                  0.994\n                \n\nR2 Adj.\n                  0.993\n                \n\nAIC\n                  1969.2\n                \n\nBIC\n                  1986.2\n                \n\nLog.Lik.\n                  -979.617\n                \n\nF\n                  11110.648\n                \n\nRMSE\n                  20.36\n                \n\n\n\n\n\n# コード7-23\nmsummary(fit_int, gof_omit = \"Log.Lik.|AIC|BIC|RMSE\")\n\n\n\n    \n\n      \n\n \n                (1)\n              \n\n\n(Intercept)\n                  20326.588\n                \n\n\n                  (108.978)\n                \n\nrd\n                  -51.872\n                \n\n\n                  (0.284)\n                \n\npromotion\n                  -191.431\n                \n\n\n                  (1.052)\n                \n\nrd × promotion\n                  0.498\n                \n\n\n                  (0.003)\n                \n\nNum.Obs.\n                  221\n                \n\nR2\n                  0.994\n                \n\nR2 Adj.\n                  0.993\n                \n\nF\n                  11110.648\n                \n\n\n\n\n\n# コード7-24\nvar_nam &lt;- c(\"rd\" = \"R&D\", \"promotion\" = \"Promotion\",\n             \"rd:promotion\" = \"R&D * Promotion\",\n             \"rd_c\" = \"R&D_c\", \"promotion_c\" = \"Promotion_c\",\n             \"rd_c:promotion_c\" = \"R&D_c * Promotion_c\",\n             \"(Intercept)\" = \"定数項\")\nInt &lt;- list()\nInt[[\"Without centering\"]] &lt;- fit_int\nInt[[\"With centering\"]] &lt;- fit_int_c\n\nmsummary(Int,\n  coef_map = var_nam,\n  title = \"Comparing Interaction Models\",\n  notes = \"Values in [ ] show 95% confidence intervals\",\n  stars = TRUE,\n  statistic = 'conf.int', conf_level = .95,\n  gof_omit = \"Log.Lik.|AIC|BIC|RMSE\")\n\n\n\n    \n\n      \n\nComparing Interaction Models\n              \n \n                Without centering\n                With centering\n              \n\n\n+ p \nValues in [ ] show 95% confidence intervals\n\n\n\nR&D\n                  -51.872***\n                  \n                \n\n\n                  [-52.433, -51.312]\n                  \n                \n\nPromotion\n                  -191.431***\n                  \n                \n\n\n                  [-193.505, -189.358]\n                  \n                \n\nR&D * Promotion\n                  0.498***\n                  \n                \n\n\n                  [0.493, 0.503]\n                  \n                \n\nR&D_c\n                  \n                  -0.918***\n                \n\n\n                  \n                  [-0.941, -0.894]\n                \n\nPromotion_c\n                  \n                  0.690***\n                \n\n\n                  \n                  [0.612, 0.769]\n                \n\nR&D_c * Promotion_c\n                  \n                  0.498***\n                \n\n\n                  \n                  [0.493, 0.503]\n                \n\n定数項\n                  20326.588***\n                  382.278***\n                \n\n\n                  [20111.797, 20541.378]\n                  [379.293, 385.263]\n                \n\nNum.Obs.\n                  221\n                  221\n                \n\nR2\n                  0.994\n                  0.994\n                \n\nR2 Adj.\n                  0.993\n                  0.993\n                \n\nF\n                  11110.648\n                  11110.648\n                \n\n\n\n\n\n# コード7-25\nmsummary(Int,\n  title = \"Comparing Interaction Models\",\n  notes = \"Values in [ ] show 95% confidence intervals\",\n  stars = TRUE,\n  statistic =  'conf.int', conf_level = .95,\n  gof_omit = \"Log.Lik.|AIC|BIC|RMSE\",\n  output = \"latex\")\n\n\n\n    \n\n      \n\nComparing Interaction Models\n              \n \n                Without centering\n                With centering\n              \n\n\n+ p \\num{\nValues in [ ] show 95\\% confidence intervals\n\n\n\n(Intercept)\n                  \\num{20326.588}***\n                  \\num{382.278}***\n                \n\n\n                  [\\num{20111.797}, \\num{20541.378}]\n                  [\\num{379.293}, \\num{385.263}]\n                \n\nrd\n                  \\num{-51.872}***\n                  \n                \n\n\n                  [\\num{-52.433}, \\num{-51.312}]\n                  \n                \n\npromotion\n                  \\num{-191.431}***\n                  \n                \n\n\n                  [\\num{-193.505}, \\num{-189.358}]\n                  \n                \n\nrd × promotion\n                  \\num{0.498}***\n                  \n                \n\n\n                  [\\num{0.493}, \\num{0.503}]\n                  \n                \n\nrd\\_c\n                  \n                  \\num{-0.918}***\n                \n\n\n                  \n                  [\\num{-0.941}, \\num{-0.894}]\n                \n\npromotion\\_c\n                  \n                  \\num{0.690}***\n                \n\n\n                  \n                  [\\num{0.612}, \\num{0.769}]\n                \n\nrd\\_c × promotion\\_c\n                  \n                  \\num{0.498}***\n                \n\n\n                  \n                  [\\num{0.493}, \\num{0.503}]\n                \n\nNum.Obs.\n                  \\num{221}\n                  \\num{221}\n                \n\nR2\n                  \\num{0.994}\n                  \\num{0.994}\n                \n\nR2 Adj.\n                  \\num{0.993}\n                  \\num{0.993}\n                \n\nF\n                  \\num{11110.648}\n                  \\num{11110.648}",
    "crumbs": [
      "第2部 仮説検証型データ分析",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>第7章</span>"
    ]
  },
  {
    "objectID": "chapter08.html",
    "href": "chapter08.html",
    "title": "6  第8章 消費者の選択と離散選択モデル",
    "section": "",
    "text": "6.1 顕示選好の理論\nKreps (1988) “Notes on the Theory of Choice”に基づいて，単一個人意思決定モデルの基礎的な考え方を説明します。\n「選択」(choice)という現象は，ある集合Aがある個人にとっての実際に選択可能な選択肢の集合であったときに，その中から個人によって1つの選択肢a \\in Aが選ばれる，という現象をいいます。 ここに，「選ぶ」というのは，第三者に観察できる行為として選ぶ，ということに限って用いられます。 また，問題となっている集合Aの各要素a \\in Aを「選択肢」(alternative)と呼びます。\n選択現象を問題にしている選択肢aが確率的構造を持っているとき，その選択肢をとくにクジ(lottery)と呼びます。\n説明するべき対象を選択肢とします。\nX \\supseteq A \\mapsto a\nここでAは選択肢の集合で，aはその選択肢を選んだ結果となります。Xは整合性を問題にできる選択肢集合のいちばん最大のもの，となります。\nX上の，この人の選択関数 \nC : X \\supseteq A \\mapsto C(A) \\subseteq X\n が安定的に存在すると仮定します。 ここでC(A)は，Aの中からこの人が選んだ選択肢集合を表します。\nXを考察する選択行動で，選択の対象となりうる潜在的な選択肢を集めた集合を表す。 選択集合とは，あるA \\in \\mathcal{P}(X)が実際に選択可能な選択肢の集合であったときに，その中から1つの選択肢が選ばれる現象をいいます。 「選ばれる」といういうとき，現に選ばれた1つの選択肢以外にも「それでも同様に良かった」というものがあるとき，それらの「そのどれでも良かった」選択肢を全て集めた集合Cを，Aからの選択結果とみなします。\n選択関数を定義すると，\nC: \\mathcal{P}(X) \\to \\mathcal{P}(X)が， \n\\forall A \\in \\mathcal{P}(X); \\  C(A) \\subseteq A\n であるとき，X上の選択関数(choice function)である，といいます。 ここで，\\mathcal{P}(X)は，Xの部分集合1つ1つを全部集めてできる冪集合(power set)のうち，Xの中から二者択一の結果だけを集めたデータを表します。",
    "crumbs": [
      "第2部 仮説検証型データ分析",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>第8章 消費者の選択と離散選択モデル</span>"
    ]
  },
  {
    "objectID": "part03.html",
    "href": "part03.html",
    "title": "第3部 探索型データ分析",
    "section": "",
    "text": "第9章では観察重視アプローチ、第10章ではセグメントとクラスター分析を、第11章では探索的因子分析、第12章では価格感応度測定(PSM)について学びます。 第9章は観察重視アプローチと理論重視アプローチを学習しますが、Rコードが出てこないので、ここでは割愛します。",
    "crumbs": [
      "第3部 探索型データ分析"
    ]
  },
  {
    "objectID": "chapter10.html",
    "href": "chapter10.html",
    "title": "7  第10章 セグメントとクラスター分析",
    "section": "",
    "text": "7.1 階層的クラスター分析\nクラスター分析(cluster analysis)は、観測値をいくつかのグループに分ける手法です。ここでは、階層的クラスター分析と非階層的クラスター分析(K-means法)を学習します。\nデータの中から類似している観測値を段階的にクラスターとしてまとめて、最終的に1つのクラスターになるまで繰り返す方法です。 類似度は距離で測定され、距離が近いほど類似しているとみなされます。 距離概念として、\nなどがあります。 デンドログラム(dendrogram)という樹形図を使って、クラスターの結合過程を視覚的に表現します。\n2023年実施の消費者調査アンケートデータを使って、階層的クラスター分析を実行してみます。 必要なパッケージを読み込みます。\nそしてデータを読み込みます。 read_xlsx()関数の引数として，\npacman::p_load(tidyverse, readxl, cluster, factoextra, ggrepel, useful)\n# コード10-1\ndf_cons &lt;- read_xlsx(\n  path = \"data/回答データ【消費者調査2023年度下期調査】.xlsx\",\n  sheet = \"回答データ【共通調査2023年度下期】\",\n  na = \" \"\n  )\n読み込んだデータをstr()で確認します。\ndf_cons |&gt;str()\n\ntibble [5,364 × 992] (S3: tbl_df/tbl/data.frame)\n $ 2023年下期no: num [1:5364] 1 2 3 4 7 8 9 10 11 12 ...\n $ 県番号      : num [1:5364] 13 13 27 14 13 13 14 11 25 14 ...\n $ 地域分類    : num [1:5364] 3 3 6 3 3 3 3 3 6 3 ...\n $ 性別        : num [1:5364] 2 1 1 1 1 1 2 2 1 2 ...\n $ 年齢        : num [1:5364] 38 42 25 26 30 33 52 53 36 26 ...\n $ 年齢階層    : num [1:5364] 3 4 2 2 3 3 5 5 3 2 ...\n $ 性年代      : num [1:5364] 11 4 2 2 3 3 13 13 3 10 ...\n $ 結婚有無    : num [1:5364] 2 2 1 1 1 1 1 2 1 2 ...\n $ q1          : num [1:5364] 2 1 1 1 1 1 2 2 1 2 ...\n $ q2t         : num [1:5364] 38 42 25 26 30 33 52 53 36 26 ...\n $ q3          : num [1:5364] 13 13 27 14 13 13 14 11 25 14 ...\n $ q4          : num [1:5364] 1 1 2 2 2 2 2 1 2 1 ...\n $ q5          : num [1:5364] 8 2 7 3 3 3 3 8 4 4 ...\n $ q6          : num [1:5364] 2 2 3 4 1 1 1 2 1 2 ...\n $ q7_1        : num [1:5364] 1 8 2 10 3 5 6 1 5 5 ...\n $ q7_2        : num [1:5364] 4 9 3 10 NA NA NA 4 NA 8 ...\n $ q8          : num [1:5364] 4 4 2 5 2 2 4 1 4 4 ...\n $ q9          : num [1:5364] 1 4 1 2 2 4 1 5 6 5 ...\n $ q10         : num [1:5364] 4 7 2 7 1 1 3 5 NA 5 ...\n $ q11_1       : num [1:5364] 5 4 1 3 4 2 4 2 3 2 ...\n $ q11_2       : num [1:5364] 4 5 2 3 4 2 3 2 3 2 ...\n $ q11_3       : num [1:5364] 4 5 2 3 3 2 4 2 3 2 ...\n $ q11_4       : num [1:5364] 4 4 3 3 4 2 4 2 3 2 ...\n $ q11_5       : num [1:5364] 4 4 3 4 4 2 4 2 3 2 ...\n $ q11_6       : num [1:5364] 4 4 3 3 3 2 4 2 3 2 ...\n $ q11_7       : num [1:5364] 4 5 2 3 4 1 4 2 3 2 ...\n $ q11_8       : num [1:5364] 4 4 3 3 4 1 3 2 3 2 ...\n $ q11_9       : num [1:5364] 4 4 3 2 4 2 5 2 3 3 ...\n $ q11_10      : num [1:5364] 4 5 4 3 3 2 3 2 3 3 ...\n $ q11_11      : num [1:5364] 4 5 3 3 4 2 4 2 3 2 ...\n $ q11_12      : num [1:5364] 4 4 3 3 3 1 4 2 3 2 ...\n $ q11_13      : num [1:5364] 4 4 2 3 3 1 3 3 3 2 ...\n $ q11_14      : num [1:5364] 4 4 2 3 4 1 4 4 3 2 ...\n $ q11_15      : num [1:5364] 4 4 3 4 4 2 3 4 3 2 ...\n $ q11_16      : num [1:5364] 4 4 3 3 4 2 5 3 3 2 ...\n $ q11_17      : num [1:5364] 4 5 3 3 5 2 4 3 3 2 ...\n $ q11_18      : num [1:5364] 4 4 2 3 4 2 4 3 3 3 ...\n $ q11_19      : num [1:5364] 4 5 2 3 5 2 5 3 3 4 ...\n $ q11_20      : num [1:5364] 4 4 3 3 4 2 4 3 3 2 ...\n $ q11_21      : num [1:5364] 4 4 3 3 5 2 3 3 3 4 ...\n $ q11_22      : num [1:5364] 4 4 3 3 4 2 3 3 3 3 ...\n $ q11_23      : num [1:5364] 4 4 4 3 4 1 5 3 3 2 ...\n $ q11_24      : num [1:5364] 4 5 3 3 5 1 4 3 3 2 ...\n $ q11_25      : num [1:5364] 4 4 3 4 4 1 4 3 3 2 ...\n $ q12_1       : num [1:5364] 2 2 3 4 1 3 3 2 3 2 ...\n $ q12_2       : num [1:5364] 2 1 4 3 2 3 2 5 3 4 ...\n $ q12_3       : num [1:5364] 2 2 3 3 1 4 2 5 3 4 ...\n $ q12_4       : num [1:5364] 2 2 3 3 1 4 2 5 3 4 ...\n $ q12_5       : num [1:5364] 2 1 4 3 2 5 3 5 3 4 ...\n $ q13_1       : num [1:5364] 2 2 3 4 2 4 2 2 2 2 ...\n $ q13_2       : num [1:5364] 2 2 3 3 2 5 2 2 2 3 ...\n $ q13_3       : num [1:5364] 2 1 3 3 2 5 2 3 2 2 ...\n $ q13_4       : num [1:5364] 4 5 3 3 5 1 3 3 1 2 ...\n $ q14_1       : num [1:5364] 4 3 3 3 3 2 2 4 3 2 ...\n $ q14_2       : num [1:5364] 4 4 3 3 3 2 2 4 3 3 ...\n $ q14_3       : num [1:5364] 4 4 3 3 3 1 2 4 3 4 ...\n $ q14_4       : num [1:5364] 4 4 3 3 2 1 4 4 3 3 ...\n $ q14_5       : num [1:5364] 4 4 3 3 3 2 5 4 3 3 ...\n $ q14_6       : num [1:5364] 4 5 2 2 3 2 4 4 4 4 ...\n $ q14_7       : num [1:5364] 4 4 3 3 4 2 2 3 3 3 ...\n $ q14_8       : num [1:5364] 4 5 3 4 3 2 2 3 3 3 ...\n $ q14_9       : num [1:5364] 4 4 3 3 5 2 3 3 3 4 ...\n $ q14_10      : num [1:5364] 4 5 2 3 5 1 4 3 3 4 ...\n $ q14_11      : num [1:5364] 4 5 3 3 4 1 2 3 4 2 ...\n $ q14_12      : num [1:5364] 4 4 3 3 3 1 4 3 3 3 ...\n $ q14_13      : num [1:5364] 4 4 3 3 4 2 4 3 3 4 ...\n $ q14_14      : num [1:5364] 4 4 3 3 3 2 2 3 3 3 ...\n $ q14_15      : num [1:5364] 4 5 3 3 3 2 4 3 4 3 ...\n $ q14_16      : num [1:5364] 4 5 2 3 4 1 2 3 3 3 ...\n $ q14_17      : num [1:5364] 4 5 2 3 4 1 4 4 4 3 ...\n $ q15_1       : num [1:5364] 1 2 3 3 2 4 3 3 3 2 ...\n $ q15_2       : num [1:5364] 2 2 3 3 3 5 2 3 3 4 ...\n $ q15_3       : num [1:5364] 2 2 3 3 2 5 2 3 3 3 ...\n $ q15_4       : num [1:5364] 2 1 3 2 3 5 2 3 3 2 ...\n $ q15_5       : num [1:5364] 2 2 3 3 3 4 3 3 3 2 ...\n $ q15_6       : num [1:5364] 2 2 3 2 2 4 1 3 2 3 ...\n $ q15_7       : num [1:5364] 2 2 5 2 3 4 2 3 3 3 ...\n $ q16_1       : num [1:5364] 2 1 3 4 3 3 3 2 4 2 ...\n $ q16_2       : num [1:5364] 2 2 3 3 3 4 4 3 4 2 ...\n $ q16_3       : num [1:5364] 2 2 3 3 3 4 2 3 3 3 ...\n $ q16_4       : num [1:5364] 2 2 3 3 3 4 3 3 3 3 ...\n $ q17_1.01    : num [1:5364] 0 1 0 0 1 1 0 0 0 1 ...\n $ q17_1.02    : num [1:5364] 0 1 0 0 0 0 0 0 0 0 ...\n $ q17_1.03    : num [1:5364] 0 0 0 0 0 0 0 0 0 1 ...\n $ q17_1.04    : num [1:5364] 0 0 0 0 0 0 0 0 0 0 ...\n $ q17_1.05    : num [1:5364] 0 0 0 0 0 0 0 0 0 0 ...\n $ q17_1.06    : num [1:5364] 0 0 0 0 0 0 0 0 0 0 ...\n $ q17_1.07    : num [1:5364] 0 0 0 0 0 0 0 0 0 0 ...\n $ q17_1.08    : num [1:5364] 0 0 0 0 0 0 0 0 0 0 ...\n $ q17_1.09    : num [1:5364] 0 0 0 0 0 0 0 0 0 0 ...\n $ q17_1.10    : num [1:5364] 0 0 0 0 1 0 0 0 0 0 ...\n $ q17_1.11    : num [1:5364] 0 0 0 0 0 0 0 1 0 0 ...\n $ q17_1.12    : num [1:5364] 0 0 0 0 0 0 0 0 0 0 ...\n $ q17_1.13    : num [1:5364] 0 0 0 0 1 0 0 1 0 0 ...\n $ q17_1.14    : num [1:5364] 0 0 0 0 0 0 0 0 0 0 ...\n $ q17_1.15    : num [1:5364] 0 0 0 0 0 0 0 0 0 0 ...\n $ q17_1.16    : num [1:5364] 0 0 0 0 0 0 0 0 0 0 ...\n $ q17_1.17    : num [1:5364] 0 1 0 0 1 0 0 0 0 0 ...\n $ q17_1.18    : num [1:5364] 0 0 0 0 0 0 0 0 0 0 ...\n  [list output truncated]\n992変数，5364観測値からなるデータを読み込みました。 東京都(13)と兵庫県(28)の回答者を対象に，ブランド志向性(q12_4)と価格志向性(q13_3)の2変数を使ってクラスター分析を実行します。\n教科書では，カテゴリー変数の数値を文字列に変換するために，case_when()関数を使っていますが， この処理だと変数の型が文字列となり，カテゴリー変数としてRが認識しなくなります。 そこでここでは，factor()関数を使って，変数の型を因子型に変換し，ラベルを付与する方法を採用します。\n# 東京と兵庫の県番号リスト作成\nken_number   &lt;- c(13, 28)\n# 因子型のラベル作成\npref_labels  &lt;- c(\"Tokyo\", \"Hyogo\")\ngender_label &lt;- c(\"Male\", \"Female\")\nmarital_label &lt;- c(\"Married\", \"Not Married\")\n\n# 回答者と項目を抽出\ndf_cons &lt;- df_cons |&gt;\n  select(県番号, 性別, 年齢, 結婚有無, q12_4, q13_3) |&gt;\n  filter(\n    県番号 %in% ken_number, # 東京と兵庫の回答者\n    q12_4 != 999,           # 欠損値は999\n    q13_3 != 999\n  ) |&gt;\n  mutate(\n    q12_4 = 6 - q12_4, # 尺度を反転\n    q13_3 = 6 - q13_3, # 尺度を反転\n    Pref       = factor(県番号,  levels  = ken_number, labels = pref_labels),\n    Gender     = factor(性別,    levels  = c(1, 2), labels = gender_label),\n    MaritalSt. = factor(結婚有無, levels = c(1, 2), labels = marital_label)\n  )\nクラスター分析を実行する関数の引数は数値データのみである必要があるので，select()で必要な変数だけを抽出し，オブジェクトclus_consに格納します。\nagnes()関数を使って階層的クラスター分析を実行します。引数として，\nを指定します。 実行結果をHier1に格納し，pltree()関数でデンドログラムを作成します。\nclus_cons &lt;- df_cons |&gt; select(q12_4, q13_3)\n\n\nHier1 &lt;- agnes(\n  clus_cons, # クラスター分析対象データ\n  metric = \"euclidian\", # 距離尺度\n  method = \"ward\", # クラスター結合方法\n  stand = TRUE # 変数の標準化\n  )\n\npltree(Hier1) # デンドログラムの作成\n次に，hclust()関数を使って階層的クラスター分析を実行します。 階層別クラスターの分析手順は以下の通りです。\nalt_Hier &lt;- clus_cons |&gt;\n  dist(\"euclidian\") |&gt; # ユークリッド距離の計算\n  hclust(\"ward.D\")  # ウォード法による階層的クラスター分析\nalt_Hier |&gt;\n  fviz_dend(\n    k = 4,  # クラスター数\n    rect = TRUE, # クラスター枠の表示\n    rect_border = TRUE # クラスター枠の色表示\n  )\n# コード10-5\nfviz_nbclust(\n  clus_cons,  # クラスター分析対象データ\n  kmeans,  # k-means法\n  method = \"wss\" # クラスター内変動の総和\n  )\nalt_Hier |&gt;\n  fviz_dend(\n    k = 5, # クラスター数\n    rect = TRUE, # クラスター枠の表示\n    rect_border = TRUE # クラスター枠の色表示\n  )\n# 乱数の種を設定\nset.seed(343)\n\n# k-means法による非階層的クラスター分析\nK_shopping &lt;- kmeans(clus_cons, 5)\nK_shopping\n\nK-means clustering with 5 clusters of sizes 80, 298, 760, 592, 243\n\nCluster means:\n     q12_4    q13_3\n1 1.000000 3.850000\n2 2.738255 4.218121\n3 3.417105 2.792105\n4 2.552365 1.876689\n5 4.300412 4.222222\n\nClustering vector:\n   [1] 5 5 5 4 3 3 3 4 2 3 3 1 3 3 3 3 4 3 3 4 2 4 5 3 2 4 3 4 5 4 3 3 3 4 3 4 3\n  [38] 4 3 3 4 5 4 3 3 4 3 3 4 2 4 2 2 4 4 2 3 3 3 3 4 3 4 3 2 1 2 1 3 4 3 4 2 4\n  [75] 2 3 5 3 4 4 4 3 4 3 2 4 3 2 3 3 3 3 4 2 3 3 3 4 4 3 3 3 4 3 3 3 4 4 3 1 3\n [112] 3 3 3 4 4 3 4 5 4 4 5 3 3 4 3 4 4 4 3 3 3 4 1 2 4 3 2 3 1 4 3 2 4 3 3 4 4\n [149] 3 2 5 2 4 2 3 3 3 4 3 3 4 3 4 4 3 4 4 3 3 4 4 3 2 4 5 3 2 4 3 4 3 3 3 3 3\n [186] 4 3 3 3 3 3 2 4 3 3 2 4 4 4 3 2 3 3 4 4 1 3 3 2 4 3 5 3 3 3 4 4 5 3 2 1 4\n [223] 5 3 5 3 4 4 5 3 4 5 3 4 3 3 4 4 5 3 3 3 5 4 3 4 2 3 2 4 3 4 3 3 4 5 4 2 3\n [260] 3 3 3 5 2 5 4 3 2 3 5 1 4 2 3 4 3 4 3 4 3 2 1 3 3 3 2 3 4 4 2 3 4 3 4 4 3\n [297] 3 3 2 4 3 5 4 2 2 4 4 4 4 5 3 1 3 4 4 4 3 3 5 4 5 4 4 3 2 2 4 4 5 4 3 4 5\n [334] 3 3 4 4 3 3 3 2 1 4 3 4 3 4 3 5 5 2 3 1 2 1 3 3 3 4 2 3 4 4 2 3 3 2 2 3 3\n [371] 4 3 3 3 3 3 3 5 3 3 4 4 3 4 3 2 4 3 4 5 3 2 4 2 3 3 4 3 3 3 3 4 4 4 1 4 3\n [408] 4 3 2 3 3 3 3 3 4 3 1 2 4 2 5 2 3 2 3 2 4 2 3 2 3 4 3 3 3 3 3 2 3 4 3 3 3\n [445] 3 3 3 5 3 3 3 1 3 3 4 4 3 2 3 5 3 4 1 5 4 4 3 2 3 3 4 3 5 4 3 4 4 3 3 4 5\n [482] 4 3 4 2 3 5 4 4 4 3 4 3 4 3 3 4 5 5 3 3 3 5 3 3 1 5 3 4 3 4 5 3 2 2 5 5 3\n [519] 2 3 3 4 2 4 3 3 3 2 5 2 4 5 5 3 3 5 3 4 2 3 3 3 3 3 3 4 4 1 4 3 3 4 2 5 4\n [556] 3 4 3 3 2 5 4 5 3 3 4 5 4 3 2 2 4 4 3 2 4 2 3 2 3 3 2 3 3 3 4 5 3 4 3 3 4\n [593] 2 4 3 3 4 3 4 3 4 3 3 4 3 2 2 3 3 3 2 4 3 4 2 5 5 3 5 3 3 5 3 4 3 1 3 2 3\n [630] 3 5 1 4 3 5 3 2 3 2 4 5 2 3 1 4 4 3 2 4 3 4 3 4 3 2 4 3 4 4 3 4 3 5 4 3 3\n [667] 3 3 3 5 2 3 2 3 4 4 3 5 3 3 4 1 3 4 1 3 5 3 5 4 5 3 3 4 2 3 3 5 2 3 3 3 4\n [704] 3 3 4 3 3 3 3 3 5 4 1 2 3 2 4 2 2 3 5 3 3 3 5 3 4 3 5 3 2 3 4 4 5 4 3 1 3\n [741] 4 3 5 4 3 1 3 3 4 4 3 5 4 3 4 4 4 2 3 4 3 5 3 3 3 4 4 3 1 3 5 2 4 1 2 3 2\n [778] 3 2 3 4 3 5 5 4 3 4 4 3 2 3 3 3 1 3 3 3 3 2 4 4 3 3 2 3 4 4 3 3 4 3 5 4 3\n [815] 4 3 4 1 4 1 4 3 4 5 2 4 2 3 4 3 2 5 4 3 4 4 3 4 2 5 3 2 2 4 3 4 4 4 4 3 5\n [852] 3 2 4 5 4 4 5 2 2 3 1 3 4 5 5 3 2 3 3 5 2 4 3 3 2 4 2 3 1 3 2 2 2 3 2 5 1\n [889] 4 4 5 5 5 4 2 5 2 3 4 1 4 3 5 5 3 2 4 4 4 3 2 2 4 3 3 4 3 3 3 3 3 2 3 2 3\n [926] 5 5 4 3 4 3 4 4 3 1 2 4 5 4 3 5 1 2 4 5 4 4 5 3 3 4 3 4 4 3 4 2 4 2 4 5 4\n [963] 3 2 4 5 4 2 4 2 3 4 3 4 3 2 4 2 3 2 3 4 2 4 2 3 3 3 2 2 4 1 3 4 1 4 3 4 4\n[1000] 3 5 4 2 5 4 5 2 3 3 3 4 3 4 3 3 4 3 3 4 4 2 3 3 5 3 2 5 3 3 3 3 4 3 4 4 5\n[1037] 2 4 3 4 2 3 2 2 4 3 3 3 4 4 2 5 3 3 3 4 3 3 5 4 4 4 2 3 4 5 1 4 3 1 2 5 4\n[1074] 4 3 4 5 4 4 3 4 3 3 4 4 4 3 3 3 4 2 4 2 4 3 2 4 4 3 3 2 3 5 5 4 3 3 5 3 4\n[1111] 2 2 3 4 5 3 4 5 4 4 3 3 3 3 3 3 4 4 3 3 4 4 3 3 4 3 2 4 5 5 5 5 2 4 3 4 3\n[1148] 4 4 2 5 4 3 2 2 3 2 4 3 3 4 4 5 3 2 2 3 4 4 2 4 5 3 5 1 4 3 2 5 3 4 4 3 3\n[1185] 4 1 5 2 4 5 3 3 4 4 3 4 3 5 5 2 3 2 3 4 4 3 2 4 4 3 2 4 3 3 3 2 5 4 1 3 5\n[1222] 4 4 3 3 3 3 4 4 2 3 4 2 5 5 4 5 4 5 2 5 2 5 4 3 3 4 3 5 3 4 4 3 4 4 4 3 3\n[1259] 2 4 2 3 4 4 4 3 4 2 4 2 4 3 4 3 2 2 4 5 5 4 3 3 3 4 4 2 3 3 4 4 3 3 5 1 4\n[1296] 3 4 3 2 3 4 3 3 4 5 3 3 4 3 4 3 2 4 4 3 3 3 5 3 4 3 5 4 4 3 4 3 5 1 4 3 1\n[1333] 2 4 4 5 3 4 4 3 3 3 4 3 3 5 4 3 1 3 3 5 3 3 3 4 2 3 5 3 2 4 3 4 1 3 4 1 5\n[1370] 3 4 3 3 3 4 3 3 5 4 5 4 3 4 2 4 5 2 4 3 3 5 5 3 2 4 5 4 4 3 3 2 3 2 2 3 3\n[1407] 4 4 5 3 4 2 3 2 3 1 2 1 2 3 2 3 3 3 4 4 1 4 2 5 3 5 2 4 4 3 4 4 4 5 3 2 3\n[1444] 1 5 3 4 3 3 3 2 4 3 4 4 3 4 3 2 4 3 4 2 4 3 3 5 4 3 5 4 2 5 4 4 2 3 2 3 3\n[1481] 3 2 5 5 5 4 4 1 3 4 3 4 3 2 5 3 4 3 3 5 1 4 4 4 3 3 3 3 4 3 4 3 4 2 3 3 3\n[1518] 3 5 4 5 5 3 2 4 3 4 4 3 3 4 3 4 3 3 2 4 4 4 5 2 4 4 1 3 3 3 5 3 3 5 3 3 3\n[1555] 3 5 4 3 2 2 4 3 3 2 3 3 3 3 3 4 4 5 5 4 2 4 3 2 3 4 4 3 1 4 2 1 5 4 2 4 3\n[1592] 3 2 3 3 4 5 3 2 2 4 1 3 2 5 3 3 3 2 4 5 5 5 4 3 5 5 4 2 4 3 5 3 1 4 5 3 2\n[1629] 4 5 5 3 2 3 3 4 1 3 5 2 3 3 2 4 3 2 3 2 3 5 3 2 2 5 3 2 4 4 4 3 4 2 4 2 3\n[1666] 2 4 2 5 5 1 3 4 2 3 5 3 3 5 5 3 4 4 2 2 4 2 4 3 4 4 4 3 3 2 2 2 4 5 2 3 3\n[1703] 5 1 3 4 5 2 3 5 5 3 2 2 4 3 3 5 3 4 4 3 3 5 3 4 4 4 3 3 4 4 5 4 4 3 3 3 3\n[1740] 4 3 3 4 2 2 5 3 4 4 2 3 4 4 2 4 3 3 2 3 2 4 2 4 4 4 4 5 2 2 3 4 3 2 4 2 4\n[1777] 4 4 4 4 3 2 4 4 3 4 4 5 4 5 2 2 2 2 3 5 4 5 2 2 1 4 4 2 4 1 3 5 2 4 5 3 1\n[1814] 3 5 4 2 3 3 3 3 2 4 3 5 3 5 3 4 1 5 5 2 3 4 2 5 4 3 5 4 5 3 4 3 4 5 3 4 4\n[1851] 4 3 3 5 1 2 5 3 3 1 2 4 3 4 3 3 4 4 1 5 3 3 3 4 1 2 3 5 5 2 4 3 2 4 4 2 3\n[1888] 2 4 5 4 3 2 3 5 3 1 3 2 3 1 2 3 2 4 3 3 3 3 4 4 3 4 4 3 4 2 4 2 3 3 5 3 4\n[1925] 5 3 4 3 4 4 5 4 1 4 3 3 3 2 2 5 1 4 4 3 3 3 4 4 4 4 2 4 3 4 1 4 5 2 4 3 5\n[1962] 1 3 3 3 4 5 2 3 3 4 3 3\n\nWithin cluster sum of squares by cluster:\n[1]  54.2000 108.4060 401.9303 622.3750 127.0700\n (between_SS / total_SS =  66.7 %)\n\nAvailable components:\n\n[1] \"cluster\"      \"centers\"      \"totss\"        \"withinss\"     \"tot.withinss\"\n[6] \"betweenss\"    \"size\"         \"iter\"         \"ifault\"\n# コード10-8\n\nfviz_cluster(\n  K_shopping,  # k-means法の結果\n  data = clus_cons, # クラスター分析対象データ\n  geom = \"point\" # プロットの形状\n  ) +\n  labs( # タイトルと軸ラベル\n    title = \"k = 5\",\n    x = \"Brand switching(Std. score)\",\n    y = \"Price orientation(Std. score)\"\n  )\n# コード10-9\ndf_cons$cluster_id &lt;- factor(K_shopping$cluster)\n\nknitr::kable(head(df_cons), caption = \"結合データ\")\n\n\n結合データ\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n県番号\n性別\n年齢\n結婚有無\nq12_4\nq13_3\nPref\nGender\nMaritalSt.\ncluster_id\n\n\n\n\n13\n2\n38\n2\n4\n4\nTokyo\nFemale\nNot Married\n5\n\n\n13\n1\n42\n2\n4\n5\nTokyo\nMale\nNot Married\n5\n\n\n13\n1\n30\n1\n5\n4\nTokyo\nMale\nMarried\n5\n\n\n13\n1\n33\n1\n2\n1\nTokyo\nMale\nMarried\n4\n\n\n28\n1\n25\n1\n3\n3\nHyogo\nMale\nMarried\n3\n\n\n28\n1\n32\n1\n3\n3\nHyogo\nMale\nMarried\n3\n# コード10-10\n\nclus_summary &lt;- df_cons |&gt;\n  group_by(cluster_id) |&gt;\n  summarize(\n    N = n(),\n    Loyalty_m = mean(q12_4),\n    Price_m   = mean(q13_3),\n    Age_m     = mean(年齢),\n    Male_r    = sum(Gender == \"Male\") / n(),\n    Tokyo_r   = (sum(Pref == \"Tokyo\") / n()) / (1465 / 1973),\n    Married_r = sum(MaritalSt. == \"Married\") / n()\n  )\n# 表示\nknitr::kable(clus_summary, caption = \"クラスターサマリー\")\n\n\nクラスターサマリー\n\n\n\n\n\n\n\n\n\n\n\n\ncluster_id\nN\nLoyalty_m\nPrice_m\nAge_m\nMale_r\nTokyo_r\nMarried_r\n\n\n\n\n1\n80\n1.000000\n3.850000\n42.61250\n0.5125000\n0.8753925\n0.5250000\n\n\n2\n298\n2.738255\n4.218121\n38.56040\n0.5134228\n0.9400188\n0.6107383\n\n\n3\n760\n3.417105\n2.792105\n41.88816\n0.5065789\n1.0100683\n0.5618421\n\n\n4\n592\n2.552365\n1.876689\n43.79730\n0.4645270\n1.0191680\n0.4712838\n\n\n5\n243\n4.300412\n4.222222\n34.91770\n0.5102881\n1.0363938\n0.6213992",
    "crumbs": [
      "第3部 探索型データ分析",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>第10章 セグメントとクラスター分析</span>"
    ]
  },
  {
    "objectID": "chapter10.html#階層的クラスター分析",
    "href": "chapter10.html#階層的クラスター分析",
    "title": "7  第10章 セグメントとクラスター分析",
    "section": "",
    "text": "ユークリッド距離(Euclidean distance)\nマンハッタン距離(Manhattan distance)\nマハラノビス距離(Mahalanobis distance)\n\n\n\n\ntidyverse: データ操作と可視化\nreadxl: Excelデータの読み込み\ncluster: クラスター分析\nfactoextra: クラスター分析の可視化\nggrepel: グラフ上のラベル配置\nuseful: 便利な関数群\n\n\n\npath: データファイルのパスとファイル名\nsheet: 読み込むシート名\nna: 欠損値を表す文字列\n\n\n\n\n\n\n\n\n\n\nclus_cons: クラスター分析対象データ\nmetric: 距離尺度\nmethod: クラスター結合方法\nstand: 変数の標準化",
    "crumbs": [
      "第3部 探索型データ分析",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>第10章 セグメントとクラスター分析</span>"
    ]
  },
  {
    "objectID": "chapter11.html",
    "href": "chapter11.html",
    "title": "8  第11章",
    "section": "",
    "text": "pacman::p_load(psych, GPArotation, tidyverse, readxl, gt, gtExtras, dendextend, cluster, factoextra, useful, ggrepel)\n\n# コード11-1\n# install.packages(\"psych\")\n# install.packages(\"GPArotation\")\n\n# コード11-2\nfactor_exdata &lt;- readxl::read_excel(\"data/factor_ex.xlsx\", na = \".\")\n\nfactor_exdata$V5 &lt;- 8 - factor_exdata$V5\nrownames(factor_exdata) &lt;- factor_exdata$ID\n\nfactor_exdata2 &lt;- factor_exdata %&gt;%\n  select(-ID)\nknitr::kable(summary(factor_exdata2))\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nV1\nV2\nV3\nV4\nV5\nV6\n\n\n\n\n\nMin. :1.000\nMin. :2.0\nMin. :1.0\nMin. :2.0\nMin. :1.0\nMin. :2.000\n\n\n\n1st Qu.:2.000\n1st Qu.:3.0\n1st Qu.:2.0\n1st Qu.:3.0\n1st Qu.:3.0\n1st Qu.:3.000\n\n\n\nMedian :4.000\nMedian :4.0\nMedian :4.0\nMedian :4.0\nMedian :4.5\nMedian :4.000\n\n\n\nMean :3.933\nMean :3.9\nMean :4.1\nMean :4.1\nMean :4.5\nMean :4.167\n\n\n\n3rd Qu.:6.000\n3rd Qu.:5.0\n3rd Qu.:6.0\n3rd Qu.:5.0\n3rd Qu.:6.0\n3rd Qu.:4.750\n\n\n\nMax. :7.000\nMax. :7.0\nMax. :7.0\nMax. :7.0\nMax. :7.0\nMax. :7.000\n\n\n\n\n# コード11-3\nknitr::kable(cor(factor_exdata2), caption = \"相関行列\")\n\n\n相関行列\n\n\n\n\n\n\n\n\n\n\n\n\nV1\nV2\nV3\nV4\nV5\nV6\n\n\n\n\nV1\n1.0000000\n-0.0532178\n0.8730902\n-0.0861622\n0.8576366\n0.0041681\n\n\nV2\n-0.0532178\n1.0000000\n-0.1550200\n0.5722121\n-0.0197456\n0.6404649\n\n\nV3\n0.8730902\n-0.1550200\n1.0000000\n-0.2477879\n0.7778480\n-0.0180688\n\n\nV4\n-0.0861622\n0.5722121\n-0.2477879\n1.0000000\n0.0065819\n0.6404649\n\n\nV5\n0.8576366\n-0.0197456\n0.7778480\n0.0065819\n1.0000000\n0.1364029\n\n\nV6\n0.0041681\n0.6404649\n-0.0180688\n0.6404649\n0.1364029\n1.0000000\n\n\n\n\n# コード11-4\ncor.exdata &lt;- cor(factor_exdata2)\n\nVSS.scree(cor.exdata)\n\n\n\n\n\n\n\n# コード11-5\nfa &lt;- fa(r = factor_exdata2, nfactors = 2,\n  rotate = \"promax\", fm = \"ml\")\nfa\n\nFactor Analysis using method =  ml\nCall: fa(r = factor_exdata2, nfactors = 2, rotate = \"promax\", fm = \"ml\")\nStandardized loadings (pattern matrix) based upon correlation matrix\n     ML1   ML2   h2    u2 com\nV1  0.97  0.00 0.94 0.063   1\nV2 -0.02  0.75 0.56 0.437   1\nV3  0.89 -0.12 0.83 0.174   1\nV4 -0.06  0.78 0.62 0.378   1\nV5  0.89  0.11 0.79 0.205   1\nV6  0.08  0.83 0.69 0.309   1\n\n                       ML1  ML2\nSS loadings           2.54 1.89\nProportion Var        0.42 0.32\nCumulative Var        0.42 0.74\nProportion Explained  0.57 0.43\nCumulative Proportion 0.57 1.00\n\n With factor correlations of \n      ML1   ML2\nML1  1.00 -0.06\nML2 -0.06  1.00\n\nMean item complexity =  1\nTest of the hypothesis that 2 factors are sufficient.\n\ndf null model =  15  with the objective function =  4.25 with Chi Square =  111.31\ndf of  the model are 4  and the objective function was  0.21 \n\nThe root mean square of the residuals (RMSR) is  0.03 \nThe df corrected root mean square of the residuals is  0.05 \n\nThe harmonic n.obs is  30 with the empirical chi square  0.65  with prob &lt;  0.96 \nThe total n.obs was  30  with Likelihood Chi Square =  5.21  with prob &lt;  0.27 \n\nTucker Lewis Index of factoring reliability =  0.95\nRMSEA index =  0.095  and the 90 % confidence intervals are  0 0.314\nBIC =  -8.39\nFit based upon off diagonal values = 1\nMeasures of factor score adequacy             \n                                                   ML1  ML2\nCorrelation of (regression) scores with factors   0.98 0.92\nMultiple R square of scores with factors          0.96 0.84\nMinimum correlation of possible factor scores     0.92 0.68\n\n# コード11-6\nfa.diagram(fa)\n\n\n\n\n\n\n\n# コード11-7\nfs &lt;- data.frame(fa$scores)\nfactor_exdata2$rowname &lt;- rownames(factor_exdata2)\nfs$rowname &lt;- rownames(fs)\nfactor_exdata2 &lt;- left_join(factor_exdata2, fs, by = \"rowname\")\nknitr::kable(head(factor_exdata2), caption = \"結合後データ\")\n\n\n結合後データ\n\n\nV1\nV2\nV3\nV4\nV5\nV6\nrowname\nML1\nML2\n\n\n\n\n7\n3\n6\n4\n6\n4\n1\n1.3106155\n-0.2896470\n\n\n1\n3\n2\n4\n3\n4\n2\n-1.2878038\n-0.2073067\n\n\n6\n2\n7\n4\n7\n3\n3\n1.1828544\n-0.7996332\n\n\n4\n5\n4\n6\n6\n5\n4\n0.1474225\n1.0035837\n\n\n1\n2\n2\n3\n2\n2\n5\n-1.3907544\n-1.3067260\n\n\n6\n3\n6\n4\n6\n4\n6\n0.9928111\n-0.2875982\n\n\n\n\n# コード11-8\n\nex_cluster &lt;- factor_exdata2 %&gt;%\n  select(ML1, ML2)\nHier1 &lt;- agnes(ex_cluster, metric = \"euclidian\", stand = TRUE)\npltree(Hier1)\n\n\n\n\n\n\n\n# コード11-9\ncl_1 &lt;- kmeans(ex_cluster, 3)\nclus_fa &lt;- data.frame(cl_1$cluster)\nclus_fa$rowname &lt;- rownames(clus_fa)\nfactor_exdata2 &lt;- left_join(factor_exdata2, clus_fa, by = \"rowname\")\nfactor_exdata2$cl_1.cluster &lt;- factor(factor_exdata2$cl_1.cluster)\n\n# Visualizing the clusters with 2 factors\np1 &lt;- ggplot(data = factor_exdata2,\n             mapping = aes(x = ML1, y = ML2, color = cl_1.cluster))\np1 + geom_point() +\n  geom_text_repel(mapping = aes(label = rownames(factor_exdata2))) +\n  labs(x = \"Ease of use\", y = \"Design\")\n\n\n\n\n\n\n\n# コード11-10\nfactor_exdata3 &lt;- factor_exdata %&gt;%\n  select(-ID)\npca_res &lt;- pca(factor_exdata3, nfactors = 2, rotate = \"none\")\npca_res\n\nPrincipal Components Analysis\nCall: principal(r = r, nfactors = nfactors, residuals = residuals, \n    rotate = rotate, n.obs = n.obs, covar = covar, scores = scores, \n    missing = missing, impute = impute, oblique.scores = oblique.scores, \n    method = method, use = use, cor = cor, correct = 0.5, weight = NULL)\nStandardized loadings (pattern matrix) based upon correlation matrix\n     PC1  PC2   h2    u2 com\nV1  0.93 0.25 0.93 0.074 1.1\nV2 -0.30 0.80 0.72 0.277 1.3\nV3  0.94 0.13 0.89 0.106 1.0\nV4 -0.34 0.79 0.74 0.261 1.4\nV5  0.87 0.35 0.88 0.122 1.3\nV6 -0.18 0.87 0.79 0.210 1.1\n\n                       PC1  PC2\nSS loadings           2.73 2.22\nProportion Var        0.46 0.37\nCumulative Var        0.46 0.82\nProportion Explained  0.55 0.45\nCumulative Proportion 0.55 1.00\n\nMean item complexity =  1.2\nTest of the hypothesis that 2 components are sufficient.\n\nThe root mean square of the residuals (RMSR) is  0.07 \n with the empirical chi square  3.94  with prob &lt;  0.41 \n\nFit based upon off diagonal values = 0.98\n\n# コード11-11\n# データの相関行列から固有値と固有ベクトルを抽出\ncor_ex &lt;- cor(factor_exdata3)\neigen_list &lt;- eigen(cor_ex)\n\n# 固有ベクトルについての情報をオブジェクトとして定義\npc1_eig &lt;- eigen_list$vectors[, 1]\npc2_eig &lt;- eigen_list$vectors[, 2]\n\n# 固有ベクトルに，固有値の平方根を乗じる\nPC1 &lt;- pc1_eig * sqrt(eigen_list$values[1])\nPC2 &lt;- pc2_eig * sqrt(eigen_list$values[2])\nknitr::kable(data.frame(cbind(PC1, PC2)), caption = \"計算結果\")\n\n\n計算結果\n\n\nPC1\nPC2\n\n\n\n\n0.9283425\n-0.2532285\n\n\n-0.3005297\n-0.7952496\n\n\n0.9361812\n-0.1308894\n\n\n-0.3415817\n-0.7889663\n\n\n0.8687553\n-0.3507939\n\n\n-0.1766389\n-0.8711581",
    "crumbs": [
      "第3部 探索型データ分析",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>第11章</span>"
    ]
  },
  {
    "objectID": "chapter12.html",
    "href": "chapter12.html",
    "title": "9  第12章",
    "section": "",
    "text": "pacman::p_load(pricesensitivitymeter, tidyverse)\n#コード 12-1\n# install.packages(\"pricesensitivitymeter\")\n# library(pricesensitivitymeter)\n# library(tidyverse)\n\n#コード 12-2\npsm_ex &lt;- read.csv(\"data/psm_ex.csv\", na = \".\")\nhead(psm_ex)\n\n\n  \n\n\n#コード 12-3\noutput_psm &lt;- psm_analysis(\n  toocheap = \"tch\",\n  cheap = \"ch\",\n  expensive = \"ex\",\n  tooexpensive = \"tex\",\n  data = psm_ex\n)\n\nsummary(output_psm)\n\nVan Westendorp Price Sensitivity Meter Analysis\n\nAccepted Price Range: 922.5 - 1253 \nIndifference Price Point: 1101 \nOptimal Price Point: 1058 \n\n---\n157 cases with individual price preferences were analyzed (unweighted data).\nTotal data set consists of 250 cases. Analysis was limited to cases with transitive price preferences.\n(Removed: n = 93 / 37% of data)\n\n#コード 12-4\npsm_plot(output_psm) +\n  labs(\n    x = \"Price\",\n    y = \"Share of Respondents (0-1)\",\n    title = \"Price Sensitivity Meter Plot\",\n    caption = \"Shaded area: range of acceptable prices\\nData: Randomly generated\") +\n  theme_minimal()",
    "crumbs": [
      "第3部 探索型データ分析",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>第12章</span>"
    ]
  },
  {
    "objectID": "chapter05.html#区間推定",
    "href": "chapter05.html#区間推定",
    "title": "3  第5章 基礎統計学復習",
    "section": "",
    "text": "3.1.1 電球の寿命データで区間推定\n例として、次のような白熱電球の寿命データが手元にあるものとしましょう。 ここで、以下のことが分かっているものとします。\n\n平均寿命が1800時間である。\n寿命の標準偏差$$は180時間である。\n平均寿命は正規分布に従う。\n\n図にすると次のようになります。\n\naverate &lt;- 1800\nstandard_dev &lt;- 180\nrnorm(1000, mean = averate, sd = standard_dev) |&gt;\n  as_tibble() |&gt;\n  ggplot(aes(x = value)) +\n  stat_function(\n    fun = dnorm,\n    args = list(mean = averate, sd = standard_dev),\n    color = \"red\",\n    size = 1\n    ) +\n  theme_minimal()\n\n\n\n\n\n\n\n\nこの分布から抽出したと想定される16個の電球の寿命データが以下の通りです。\n\n# コード5-5\nbulb &lt;- c(# 白熱電球の寿命データ\n    1939.6, 1680.3, 1982.1, 2215.6,\n    2092.5, 1928.9, 2003.8, 1955.5,\n    1800.1, 1659.5, 2066.2, 2107.2,\n    2085.5, 1878.6, 2007.6, 1816.1\n  )\nmean(bulb)\n\n[1] 1951.194\n\nsd(bulb)\n\n[1] 154.4567\n\n\n先ほどの分布にこのデータのヒストグラムを重ねると、次のようになります。\n\n# ヒストグラムの作成\nbulb_df &lt;- tibble(lifetime = bulb)\nbulb_df |&gt; \n  ggplot(aes(x = lifetime)) +\n  geom_histogram(\n    aes(y = ..density..),\n    bins = 8,\n    fill = \"lightblue\",\n    color = \"black\",\n    alpha = 0.7\n    ) +\n  stat_function(\n    fun = dnorm,\n    args = list(mean = averate, sd = standard_dev),\n    color = \"red\",\n    size = 1\n    ) +\n  theme_minimal()\n\n\n\n\n\n\n\n\nそのとき、この手元にある16個の電球の寿命データの平均値が、母平均1800の周りでどの範囲に入るかを95％の信頼水準で推定してみましょう。\n\n# t検定の実施\nbulb_ci &lt;- t.test(bulb)\nbulb_ci$conf.int \n\n[1] 1868.890 2033.498\nattr(,\"conf.level\")\n[1] 0.95\n\n# 信頼区間の出力（デフォルトで 95％信頼水準）\n\n\n# コード5-6\nqnorm(0.025, lower.tail = FALSE)\n\n[1] 1.959964\n\n# 標準正規分布における上側 2.5％点の分位点を求める。\n\n\n# コード5-7\nn &lt;- length(bulb) # 標本サイズの計算\nz &lt;- qnorm(0.025, lower.tail = FALSE) # 上側2.5％点の分位点\nxbar &lt;- mean(bulb) # 標本平均の計算\nsigma &lt;- 180 # 母標準偏差の設定\n\n# 信頼区間の計算\nupper &lt;- xbar + z * (sigma / sqrt(n))\nlower &lt;- xbar - z * (sigma / sqrt(n))\n\n# 結果のまとめと出力\nci.bulb &lt;- matrix(c(lower, upper), nrow = 1)\ncolnames(ci.bulb) &lt;- c(\"ci.lower\", \"ci.upper\")\nknitr::kable(\n  ci.bulb, \n  caption = \"Bulb data CI (95％)\", \n  align = \"cc\"\n  )\n\n\nBulb data CI (95％)\n\n\nci.lower\nci.upper\n\n\n\n\n1862.995\n2039.392\n\n\n\n\n\n\n# コード5-8\nmean(bulb)\n\n[1] 1951.194\n\n# コード5-9\nt.test(bulb, alternative = \"two.sided\", mu = 1800)\n\n\n    One Sample t-test\n\ndata:  bulb\nt = 3.9155, df = 15, p-value = 0.001377\nalternative hypothesis: true mean is not equal to 1800\n95 percent confidence interval:\n 1868.890 2033.498\nsample estimates:\nmean of x \n 1951.194 \n\n# コード5-10\nn &lt;- length(bulb) # 標本サイズの計算\nz &lt;- qnorm(0.025, lower.tail = FALSE) # 上側2.5％点の分位点\nxbar &lt;- mean(bulb) # 標本平均の計算\nsigma &lt;- 180 # 母標準偏差の設定\nmu &lt;- 1800 # 帰無仮説の平均値 \n# Z値の計算\nZ &lt;- (xbar - mu) / (sigma / sqrt(n))\nZ\n\n[1] 3.359861\n\n\n\n# コード5-11\n# データの読み込みと前処理\nfirmdata &lt;- readxl::read_xlsx(\"data/MktRes_firmdata.xlsx\")\nfirm2018 &lt;- firmdata |&gt;\n  filter(fyear == 2018) |&gt;\n  mutate(\n    ad_dummy = ifelse(adint &gt; median(adint), 1, 0)\n    )\n# t検定の実施\nt.test(sales ~ ad_dummy, data = firm2018)\n\n\n    Welch Two Sample t-test\n\ndata:  sales by ad_dummy\nt = -3.3989, df = 85.686, p-value = 0.001029\nalternative hypothesis: true difference in means between group 0 and group 1 is not equal to 0\n95 percent confidence interval:\n -1674283.1  -438496.1\nsample estimates:\nmean in group 0 mean in group 1 \n       725009.7       1781399.3 \n\n\n\n# コード5-12\nvar.test(sales ~ ad_dummy, data = firm2018, ratio = 1)\n\n\n    F test to compare two variances\n\ndata:  sales by ad_dummy\nF = 0.10863, num df = 74, denom df = 71, p-value &lt; 2.2e-16\nalternative hypothesis: true ratio of variances is not equal to 1\n95 percent confidence interval:\n 0.06821636 0.17258882\nsample estimates:\nratio of variances \n         0.1086276 \n\n\n\n# 効果量d=0.8、検出力0.8、有意水準0.05の場合の\n# 必要標本サイズの推定\nest_n &lt;- pwr.t.test(d = 0.8, power = 0.8, sig.level = 0.05)\nest_n\n\n\n     Two-sample t test power calculation \n\n              n = 25.52458\n              d = 0.8\n      sig.level = 0.05\n          power = 0.8\n    alternative = two.sided\n\nNOTE: n is number in *each* group\n\n\n\n# コード5-15\nplot(est_n)\n\n\n\n\n\n\n\n\n\n# コード5-16\npwr.t.test(d = 0.8, n = 26, sig.level = 0.05)\n\n\n     Two-sample t test power calculation \n\n              n = 26\n              d = 0.8\n      sig.level = 0.05\n          power = 0.8074866\n    alternative = two.sided\n\nNOTE: n is number in *each* group",
    "crumbs": [
      "第2部 仮説検証型データ分析",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>第5章 基礎統計学復習</span>"
    ]
  },
  {
    "objectID": "chapter08.html#顕示選好の理論",
    "href": "chapter08.html#顕示選好の理論",
    "title": "6  第8章 消費者の選択と離散選択モデル",
    "section": "",
    "text": "6.1.1 選好モデル\n二項関係(binary relation)を定義します。 Xの（たまたま同じであることを許す）2つの要素について語られた関係が，X上の二項関係(binary relation)であるとは， X \\times Xのすべての要素(x,y)について，xはyに対してその関係にあるか，またはその関係にないか，を必ず一方をいうことができる場合を言います。\nつまり，選択肢集合Aに選択肢xとyがあり，その人の選択結果C(\\{x,y\\}) = ?を見ます。 その人が選択するものは，\n\n\\begin{aligned}\nC(\\{x,y\\}) &= \\phi \\quad \\text{$x$も$y$も選べたのに選ばなかった。}\\\\\nC(\\{x,y\\}) &= \\{x\\} \\quad xを選び，yを選ばなかった\\\\\nC(\\{x,y\\}) &= \\{y\\} \\quad yを選び，xを選ばなかった\\\\\nC(\\{x,y\\}) &= \\{x,y\\} \\quad xもyも選んだ。\n\\end{aligned}\n\n\n\n6.1.2 選好\nX 上の選択関数 C: \\mathcal{P}(X) \\rightarrow  \\mathcal{P}(X) が与えられたとき，X の(それがたまたま同じであることを許す)2つの要素についての関係を，各 (x,y) \\in X \\times X に対して，y \\not \\in C(\\{x,y\\}) なら，x は y に対してその関係にあり，y \\in C(\\{x,y\\}) なら x は y に対してその関係にない，というやり方で定められるとき，その関係(それは二項関係である)を，(選択関数 C:\\mathcal{P}(X) \\rightarrow \\mathcal{P}(X) によって生成された) X 上の強選好(strict preference)といいます。\nこの二項関係を記号 \\succ で表わし，x が y に対して強選好の関係にあるとき，x を y よりも厳密に選好する，あるいは x は y よりも厳密に選好されるといって，x \\succ y と書き，x が y に対して強選好の関係にないとき，x は y よりも厳密に選好されるわけではない，といって x \\not \\succ y と書きます。\nある X 上の強選好 \\succ は，それが定義されたもとの選択関数 C : \\mathcal{P}(X) \\rightarrow \\mathcal{P}(X)を明示する必要があるときは，\\succ _cと書く。\nx,yの二者択一の結果，C(\\{ x,y \\})を， \n\\begin{aligned}\n& x \\not \\succ y \\Longleftrightarrow y \\in      C(\\{x,y\\})\\leftarrow \\text{$x$は$y$より厳密に選好されるわけではない。}\\\\\n& x      \\succ y \\Longleftrightarrow y \\not \\in C(\\{x,y\\})\\leftarrow xはyより厳密に選好される。\n\\end{aligned}\n\nのように書いたものを，この人の(強)選好という。\nつぎに、X 上の強選好 \\succ が与えられたとき、各A \\in \\mathcal{P}(X)に対し、 \nC(A, \\succ) = \\{ x \\in A \\mid \\nexists y \\in A \\quad  \\text{s.t.} \\quad y \\succ x \\}\n を対応づける（集合体集合の）関数 C(\\cdot , \\succ) : \\mathcal{P}(X) \\rightarrow \\mathcal{P}(X) を、X 上の選択の選好モデル(preference model)といいます。\nまとめると、 \nC : \\mathcal{P}(X) \\rightarrow C(A) \\in \\mathcal{P}(X)\n のうち、「二者択一の結果を、Xの各ペア(x,y) ごとに、x \\succ y か x \\not \\succ y かを書いて、書いたものをX上の（この人の）強選好」といいます。 選好モデルとは、 \nC : \\mathcal{P}(X) \\ni A \\rightarrow C(A) \\in \\mathcal{P}(X)\n を \n\\begin{aligned}\n& C(\\cdot, \\succ) : \\mathcal{P}(X) \\ni A \\rightarrow C(A, \\succ) \\in \\mathcal{P}(X)\\\\\n& \\text{such that} \\quad C(A, \\succ) = \\{ x \\in A \\mid \\nexists y \\in A \\quad  \\text{s.t.} \\quad y \\succ x \\}\n\\end{aligned}\n となり、この選好\\succをもつ人が、実際にAに直面したときに選ぶと予測するということを意味します。 これはC(\\cdot , \\succ)のデータから予測されます。\nC(\\cdot , \\succ) : \\mathcal{P}(X) \\ni A \\rightarrow C(A, \\succ) \\in \\mathcal{P}(X)は、C : \\mathcal{P}(X) \\ni A  \\rightarrow C(A) \\in \\mathcal{P}(X)のうち、|X|^2個のデータで、C : \\mathcal{P}(X) \\ni A  \\rightarrow C(A) \\in \\mathcal{P}(X)全体の2^{|X|}個の値を予測しているのです。\n合理性モデルでは、「もし・・・なら、\\forall A \\in \\mathcal{P}; C(A, \\succ) = C(A)となります。\nふりかえると、\n\n説明する対象は、選択関数 C : \\mathcal{P}(X) \\in A  \\mapsto C(A) \\in \\mathcal{P}(X) である。\nデータを取ってくるパラメータとしての選好\\succ (つまり、X上のすべての二者択一の結果)を考えます。\n選択を説明するモデルは選好モデルは、 \nC(A, \\succ) = \\{x \\in A \\mid \\nexists y \\in A \\quad  \\text{s.t.} \\quad y \\succ x \\}\n となります。つまり、「自分より良いものが存在しない」要素だけを集めたものを意味します。\n選択理論とは、「C: \\mathcal{P}(X) \\rightarrow \\mathcal{P}(X) が･･･の条件を満たすとき、Cのうち××から作ったC(A, ××)  = C(A) 」が成り立つような「･･･」と「××」を考えます。\n\nただ、選好\\succとしてどんなものでも認めてしまうと、\n\n\\exists \\succ, \\exists A \\quad \\text{s.t.} \\quad C(A, \\succ) = \\emptyset\n となる場合があります。 たとえば、A = X = \\{x, y, z\\}で、 C(\\{x,y\\}) = \\{x\\}、 C(\\{y,z\\}) = \\{y\\}、 C(\\{x,z\\}) = \\{z\\} かつ、 C(A) \\not = \\emptyset. 場合、C(\\{x,y,z\\}) = \\emptyset となります。\nつまり、\n\nz \\succ x より x \\not \\in C(\\{x,y, z\\}, \\succ)\nx \\succ y より y \\not \\in C(\\{x,y, z\\}, \\succ)\ny \\succ z より z \\not \\in C(\\{x,y, z\\}, \\succ)\n\nすなわち、C(\\{x,y,z\\}, \\succ) = \\emptyset となります。\nでは、どのような二者択一行動を示す人なら、その人の選好モデルは完結性があるのかを考えます。 次の2つの条件が満たされるとき、選好\\succは完結性(completeness)を持つといいます。\n\n反対称性(asymmetry) : \\forall x,y \\in X;, 「x \\succ y かつ y \\succ x」ということはない。つまり二者択一行動がC(\\{x,y\\}) = \\{\\emptyset\\}ということがない。\n負推移性(negative transitivity) : \\forall x,y \\in X;, 「もし x \\not \\succ y かつ y \\not \\succ z」ならば「x \\not \\succ z」である。 つまり二者択一行動としては、もしy \\in C(\\{x,y\\}) かつ z \\in C(\\{y,z\\}) ならば、z \\in C(\\{x,z\\}) である。\n\nこれより、X 上の強選好 \\succ は、次のように定義できます。\n\n\n\n\n\n\nImportant反対称性・負推移性\n\n\n\n\n\\nexists (x,y) \\in X \\times X; \\quad \\text{s.t} \\quad x \\succ y,  \\quad y \\succ x\n であるとき、反対称的(assymmetric)である、あるいは反対称性を満たすといい、 \n\\forall x,y,z \\in X; \\quad \\text{if} \\quad x \\not \\succ y,  \\quad y \\not \\succ z, \\quad \\text{then} \\quad x \\not \\succ z\n であるとき、負推移的(negatively transitive)である、あるいは負推移性を満たすといいます\n\n\n\n\n\n\n\n\nImportant選好関係\n\n\n\nX 上の強選好 \\succ は、反対称的かつ負推移的であるとき、X上の選好関係(preference relation)であるといいます。\n\n\n選好\\succが反対称的かつ負推移的であるとき、推移的(acyclic)であるといい、 x_1 \\succ x_2 かつ x_2 \\succ x_3 かつ \\cdots かつ x_{n-1} \\succ x_n なら x_1 \\not = x_n となります。\n\n\n6.1.3 Xが有限集合の場合\nX 上の強選好 \\succ が \n\\forall x \\in X; \\quad x \\not \\succ x\n であるとき、非反射的(irreflexive)である、あるいは非反射性を満たすといいます。\n\n\n\n\n\n\nNote推移性\n\n\n\nX 上の強選好 \\succ は、 \n\\forall x, y, z \\in X; \\quad \\text{if} \\quad x \\succ y, \\ y \\succ x, \\quad \\text{then} \\quad x \\succ z\n であるとき、推移的(transitive)である、あるいは推移性を満たすといいます。\n証明は省略（背理法により示せます）。\n\n\n\n\n\n\n\n\nNote非周期性\n\n\n\n次に、X 上の強選好 \\succ は、\n\n\\begin{aligned}\n&\\forall x_1, x_2, \\cdots, x_n \\in X;\\\\\n&\\quad \\text{if} \\quad x_1 \\succ x_2, \\ x_2 \\succ x_3, \\ \\dots, \\ x_{n-1} \\succ x_n, \\quad \\text{then} \\quad x_1 \\not = x_n\n\\end{aligned}\n であるとき、非周期的(acyclic)である、あるいは非周期性を満たすといいます。\n証明は省略（帰納法により示せます）。\n\n\n\n\n\n\n\n\nImportant\n\n\n\nX 上の強選好 \\succ は、X上の選好関係ならば、非反射的かつ推移的かつ非周期的である。\n\n\nX上の選択関数 C : \\mathcal{P}(X) \\rightarrow \\mathcal{P}(X)は、\n\n\\begin{aligned}\n\\forall A \\in \\mathcal{P}(X); \\quad \\text{if} \\quad A \\not = \\emptyset \\quad \\text{then} \\quad C(A) \\not = \\emptyset\n\\end{aligned}\n であるとき、非空(nonempty)であるといいます。\nこれらの定理と定義から、次の定理が示せます。\n\n\n\n\n\n\nImportant\n\n\n\nX を有限集合(|X| &lt; \\infty)とします。 X 上の強選好\\succは、X上の(反対称的と負推移性を満たす)選好関係ならば、A \\not = \\emptysetのとき、C(\\cdot, \\succ): \\mathcal{P}(X) \\rightarrow \\mathcal{P}(X)は非空となります。\n\n\nが選好関係であるとき、Xが有限集合であれば、任意のA \\in \\mathcal{P}(X)に対し、C(A, \\succ) \\not = \\emptyset となります。\nここまでの説明により、ある個人の選択行動を説明するために必要な条件は、 ある個人が(有限の)選択肢の中から選び取るとき、その人の選好が反対称的かつ負推移的であれば、選択肢集合が非空なら、その人がもつ選択関数は非空である、ということがわかりました。",
    "crumbs": [
      "第2部 仮説検証型データ分析",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>第8章 消費者の選択と離散選択モデル</span>"
    ]
  },
  {
    "objectID": "chapter08.html#顕示選考理論",
    "href": "chapter08.html#顕示選考理論",
    "title": "6  第8章 消費者の選択と離散選択モデル",
    "section": "6.2 顕示選考理論",
    "text": "6.2 顕示選考理論\n選択肢集合Xが有限であるとします。 すると、X上の強選好\\succがX上の選好関係であるならば、 C(\\cdot , \\succ) : \\mathcal{P}(X) \\rightarrow \\mathcal{P}(X)は非空かつハウタッカーの公理(Houthakker’s axiom)を満たします。\n\n\n\n\n\n\nImportantハウタッカーの公理\n\n\n\nX上の選択関数C : \\mathcal{P}(X) \\rightarrow \\mathcal{P}(X)は、 \n\\begin{aligned}\n& \\forall x,y \\in X, \\quad \\forall A,B \\in \\mathcal{P}(X); \\\\\n& \\quad \\text{if} \\quad x,y \\in A \\cap B, \\quad x \\in C(A), \\quad  y \\in C(B)\\\\\n& \\quad \\text{then} \\quad x \\in C(B), \\quad y \\in C(A)\n\\end{aligned}\n であるとき、ハウタッカーの公理を満たす、といいます。\n\n\n具体例で説明します。 たとえば、あなたの買い物の選択肢として\n\nA=\\{\\text{みかん, リンゴ, バナナ}\\}、\nB=\\{\\text{バナナ, リンゴ, ぶどう}\\}\n\nがあるとします。\nこのとき、あなたは\n\nA の中からリンゴを選び（C(A)=\\{\\text{リンゴ}\\}）、\nB の中からバナナを選ぶ（C(B)=\\{\\text{バナナ}\\}）\n\nとします。\nリンゴとバナナはいずれも A\\cap B に含まれています。 ハウタッカーの公理は、この状況のもとでは、 選択肢集合が B に変わってもリンゴが選ばれ、 選択肢集合が A に変わってもバナナが選ばれなければならない、 ということを要請します。\nつまり、共通して含まれる選択肢については、 集合ごとに選択の優劣が入れ替わるような行動は許されない、 という選択の一貫性を表しています。\n\n\n\n\n\n\nNoteセンの\\alpha規則性\n\n\n\nX上の選択関数C : \\mathcal{P}(X) \\rightarrow \\mathcal{P}(X)は、\n\n\\begin{aligned}\n& \\forall x \\in X, \\quad \\forall A,B \\in \\mathcal{P}(X);\\\\\n& \\quad \\text{if} \\quad x \\in B \\subset A, \\quad x \\in C(A),\\\\\n& \\quad \\text{then} \\quad x \\in C(B)\n\\end{aligned}\n\nであるとき、センの\\alpha規則性(Sen’s property \\alpha)を満たす、といいます。\n\n\n\n\n\n\n\n\nTipセンの\\alpha規則性の具体例\n\n\n\nあなたの選択肢の全集合をXとし、 A=\\{\\text{みかん, リンゴ, バナナ}\\}、 B=\\{\\text{リンゴ, バナナ}\\} とします。このとき B \\subset A が成り立っています。\nいま、あなたが集合 A からリンゴを選んでいる、すなわち C(A)=\\{\\text{リンゴ}\\} であるとします。リンゴは B にも含まれています。\nセンの \\alpha 規則性は、この状況において、選択肢集合が A からその部分集合である B に縮小されても、リンゴは引き続き選ばれなければならない、すなわち C(B)=\\{\\text{リンゴ}\\} であることを要請します。\n言い換えると、ある選択肢がより大きな集合の中で選ばれていたのであれば、その選択肢を排除しない範囲で選択肢集合を減らしても、その選択肢が選ばれなくなることは許されない、という性質を表しています。\n\n\n\n\n\n\n\n\nNoteセンの\\beta規則性\n\n\n\nX上の選択関数C : \\mathcal{P}(X) \\rightarrow \\mathcal{P}(X)は、 \n\\begin{aligned}\n&\\forall x,y \\in X, \\quad \\forall A,B \\in \\mathcal{P}(X); \\\\\n&\\quad \\text{if} \\quad x,y \\in C(A), \\quad  A \\subset B, \\quad y \\in C(B), \\\\\n&\\quad \\text{then} \\quad x \\in C(B)\n\\end{aligned}\n であるとき、センの\\beta規則性(Sen’s property \\beta)を満たす、といいます。\n\n\n\n\n\n\n\n\nTipセンの\\beta規則性の具体例\n\n\n\n選択肢の全集合を X とし、 A=\\{\\text{リンゴ, バナナ}\\}、 B=\\{\\text{みかん, リンゴ, バナナ}\\} とします。このとき A \\subset B が成り立っています。\nいま、集合 A からはリンゴとバナナの両方を選んでいる、すなわち C(A)=\\{\\text{リンゴ, バナナ}\\} とします。\n次に、選択肢が増えた集合 B からはバナナを選んでいる、すなわち C(B)=\\{\\text{バナナ}\\} であるとします。\nセンの \\beta 規則性は、この状況のもとでは、集合 A で同時に選ばれていたリンゴとバナナのうち、集合 B に移ってもバナナが選ばれているのであれば、リンゴもまた集合 B から選ばれなければならない、ということを要請します。\nしたがって、この規則性を満たす選択関数では、 C(B) は \\{\\text{バナナ}\\} ではなく、少なくともリンゴを含み、たとえば C(B)=\\{\\text{リンゴ, バナナ}\\} でなければならない、ということになります。\nこの例は、集合を拡大したときに、もともと同時に選ばれていた選択肢の一部だけが残るような振る舞いを排除する性質を具体的に示しています。\n\n\nこれらの公理と規則性から次の定理が示せます。\n\n\n\n\n\n\nImportant定理\n\n\n\nX上の選択関数C : \\mathcal{P}(X) \\rightarrow \\mathcal{P}(X)が非空とします。 このとき、C: \\mathcal{P}(X) \\rightarrow \\mathcal{P}(X) がハウタッカーの公理を満たすための必要十分条件は、それがセンの\\alpha規則性と\\beta規則性を満たすことです。\n\n\n具体例で説明してみます。 たとえばあなたが買い物をしているとき、選択肢集合A = \\{豚肉, 牛肉, 鶏肉\\}の中から何かを選択する、選択問題に直面しているとします。 このとき、センの\\alpha規則性は、もしあなたがAの中から牛肉を選んだとき(C(A) = \\{牛肉\\})、選択肢集合がB = \\{牛肉, 鶏肉\\} \\subset Aに変わっても、あなたは牛肉を選ぶ、ということを意味します。\n次にセンの\\beta規則性は、もしあなたがAの中から牛肉と鶏肉を選んだとき(C(A) = \\{牛肉, 鶏肉\\})、選択肢集合がB = \\{豚肉, 牛肉, 鶏肉\\} \\supset Aに変わっても、あなたは鶏肉を選ぶ、ということを意味します。\nまた、X上の選択関数C : \\mathcal{P}(X) \\rightarrow \\mathcal{P}(X) が非空( A\\not = \\emptysetならC(A) \\not = \\emptyset )かつハウタッカーの公理を満たすならば、\\succ_cはX上の選好関係\\succであり(反対称性と負推移性を満たす)であり、しかもA \\not = \\emptysetならば、\n\n\\forall A \\in \\mathcal{P}(X); \\quad C(A, \\succ_c) = C(A)\n が成り立ちます。",
    "crumbs": [
      "第2部 仮説検証型データ分析",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>第8章 消費者の選択と離散選択モデル</span>"
    ]
  },
  {
    "objectID": "chapter08.html#センのalpha規則性の具体例",
    "href": "chapter08.html#センのalpha規則性の具体例",
    "title": "6  第8章 消費者の選択と離散選択モデル",
    "section": "6.3 センの\\alpha規則性の具体例",
    "text": "6.3 センの\\alpha規則性の具体例\nあなたの選択肢の全集合を X とし、 A={}、 B={} とします。このとき B A が成り立っています。\nいま、あなたが集合 A からリンゴを選んでいる、すなわち C(A)={} であるとします。リンゴは B にも含まれています。\nセンの 規則性は、この状況において、選択肢集合が A からその部分集合である B に縮小されても、リンゴは引き続き選ばれなければならない、すなわち C(B)={} であることを要請します。\n言い換えると、ある選択肢がより大きな集合の中で選ばれていたのであれば、その選択肢を排除しない範囲で選択肢集合を減らしても、その選択肢が選ばれなくなることは許されない、という性質を表しています。",
    "crumbs": [
      "第2部 仮説検証型データ分析",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>第8章 消費者の選択と離散選択モデル</span>"
    ]
  },
  {
    "objectID": "chapter08.html#二値選択モデル",
    "href": "chapter08.html#二値選択モデル",
    "title": "6  第8章 消費者の選択と離散選択モデル",
    "section": "6.3 二値選択モデル",
    "text": "6.3 二値選択モデル\n長々と単一個人の意思決定モデルとして、選択行動を説明してきました。 つぎに、この顕示選考理論を背景として、消費者が「買う・買わない」という観察可能な行動の結果をデータとして入手した場合の統計分析について考えてみましょう。\n\npacman::p_load(tidyverse, readxl, modelsummary, mfx, DescTools, mlogit)\n\n従属変数Yが0か1の二値であるという観察可能な行動の結果を示すものとします。 独立変数Xは、その選択に影響を与える要因を示す連続変数とします。\n\n# コード8-1\ndf1 &lt;- data.frame(\n    Y = c(0, 0, 0, 0, 0, 1, 1, 1, 1),\n    X = c(3.4, 5.22, 7.06, 2.81, 4.11, 10.34, 13.67, 15.99, 9.09)\n)\n\n従属変数Yを説明変数Xで線形回帰します。 線形回帰は、lm()関数で行います。\n\nlpm1 &lt;- lm(Y ~ X, data = df1)\npred_lpm1 &lt;- predict(lpm1)\npred_lpm1\n\n           1            2            3            4            5            6 \n-0.006342894  0.173357681  0.355032986 -0.064597476  0.063760077  0.678888967 \n           7            8            9 \n 1.007681776  1.236750640  0.555468243 \n\n\n\n# コード8-2\nchoice_df &lt;- readxl::read_xlsx(\"data/choice_data.xlsx\")\nhead(choice_df)\n\n\n  \n\n\n\n\n# コード8-3\nprobit1 &lt;- glm(y1 ~ p1 + a1,\n    family = binomial(link = probit),\n    data = choice_df\n)\nsummary(probit1)\n\n\nCall:\nglm(formula = y1 ~ p1 + a1, family = binomial(link = probit), \n    data = choice_df)\n\nCoefficients:\n            Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)  2.04117    0.22350   9.133  &lt; 2e-16 ***\np1          -0.24720    0.02213 -11.171  &lt; 2e-16 ***\na1           0.62763    0.08656   7.251 4.13e-13 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 1384.5  on 999  degrees of freedom\nResidual deviance: 1205.5  on 997  degrees of freedom\nAIC: 1211.5\n\nNumber of Fisher Scoring iterations: 3\n\n\n\n# コード8-4\nols1 &lt;- lm(y1 ~ p1 + a1,\n    data = choice_df\n)\nlogit1 &lt;- glm(y1 ~ p1 + a1,\n    family = binomial(link = logit),\n    data = choice_df\n)\nmodels &lt;- list()\nmodels[[\"Linear probability model\"]] &lt;- ols1\nmodels[[\"Probit model\"]] &lt;- probit1\nmodels[[\"Logit model\"]] &lt;- logit1\nmodelsummary(models,\n    title = \"モデル比較\",\n    notes = \"Values in [ ] show robust standard errors\",\n    stars = TRUE,\n    statistic = \"std.error\",\n    vcov = \"robust\",\n    gof_map = \"nobs\"\n)\n\n\n\n    \n\n    \n    \n      \n        \n        モデル比較\n              \n                 \n                Linear probability model\n                Probit model\n                Logit model\n              \n        \n        + p &lt; 0.1, * p &lt; 0.05, ** p &lt; 0.01, *** p &lt; 0.001\nValues in [ ] show robust standard errors\n        \n                \n                  (Intercept)\n                  1.196***\n                  2.041***\n                  3.332***\n                \n                \n                  \n                  (0.065)\n                  (0.212)\n                  (0.361)\n                \n                \n                  p1\n                  -0.085***\n                  -0.247***\n                  -0.404***\n                \n                \n                  \n                  (0.006)\n                  (0.021)\n                  (0.036)\n                \n                \n                  a1\n                  0.221***\n                  0.628***\n                  1.035***\n                \n                \n                  \n                  (0.029)\n                  (0.087)\n                  (0.145)\n                \n                \n                  Num.Obs.\n                  1000\n                  1000\n                  1000\n                \n        \n      \n    \n\n\n# 適合度指標において，サンプルサイズ (\"nobs\") のみ表示するという指示\n\n\n# コード8-5\n# Average Marginal Effects（限界効果の平均）\nprobit1_ame &lt;- probitmfx(y1 ~ p1 + a1,\n    data = choice_df, atmean = FALSE\n)\nprobit1_ame\n\nCall:\nprobitmfx(formula = y1 ~ p1 + a1, data = choice_df, atmean = FALSE)\n\nMarginal Effects:\n        dF/dx  Std. Err.        z     P&gt;|z|    \np1 -0.0847786  0.0060787 -13.9469 &lt; 2.2e-16 ***\na1  0.2188866  0.0289816   7.5526 4.266e-14 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\ndF/dx is for discrete change for the following variables:\n\n[1] \"a1\"\n\n\n\n# コード8-7\n# Marginal Effects at Mean（平均値における限界効果）\nprobit1_mem &lt;- probitmfx(y1 ~ p1 + a1,\n    data = choice_df, atmean = TRUE\n)\nprobit1_mem\n\nCall:\nprobitmfx(formula = y1 ~ p1 + a1, data = choice_df, atmean = TRUE)\n\nMarginal Effects:\n        dF/dx  Std. Err.        z     P&gt;|z|    \np1 -0.0984235  0.0088074 -11.1750 &lt; 2.2e-16 ***\na1  0.2446609  0.0324366   7.5427 4.602e-14 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\ndF/dx is for discrete change for the following variables:\n\n[1] \"a1\"\n\n\n\n# コード8-8\nmarginal &lt;- c(\n    \"p1 marginal\" = \"p1\",\n    \"a1 marginal\" = \"a1\"\n)\n\nmarg_model &lt;- list(\n    \"(1) Probit_AME\" &lt;- probit1_ame,\n    \"(2) Probit_MEM\" &lt;- probit1_mem\n)\n\nmarg_sum &lt;- modelsummary(\n    marg_model,\n    statistic = \"std.error\",\n    coef_map = marginal,\n    stars = TRUE,\n    shape = term:component ~ model,\n    add_rows = data.frame(\n        \"Marginal effect type\",\n        \"Average Marginal Effect\",\n        \"Marginal Effect at Mean\"\n    ),\n    title = \"限界効果サマリー\",\n    gof_map = \"nobs\"\n)\nmarg_sum\n\n\n\n    \n\n    \n    \n      \n        \n        限界効果サマリー\n              \n                 \n                (1)\n                (2)\n              \n        \n        + p &lt; 0.1, * p &lt; 0.05, ** p &lt; 0.01, *** p &lt; 0.001\n        \n                \n                  p1\n                  -0.085***\n                  -0.098***\n                \n                \n                  \n                  (0.006)\n                  (0.009)\n                \n                \n                  a1\n                  0.219***\n                  0.245***\n                \n                \n                  \n                  (0.029)\n                  (0.032)\n                \n                \n                  Num.Obs.\n                  1000\n                  1000\n                \n                \n                  Marginal effect type\n                  Average Marginal Effect\n                  Marginal Effect at Mean\n                \n        \n      \n    \n\n\n\n\n# コード8-9\nDescTools::PseudoR2(probit1)\n\n McFadden \n0.1293345 \n\n# コード8-10\n\n# 価格差変数作成\nchoice_df &lt;- choice_df %&gt;%\n    mutate(p_ratio = p1 - p2)\n\nprobit2 &lt;- glm(y1 ~ p_ratio + a1 + a2,\n    family = binomial(link = probit),\n    data = choice_df\n)\nsummary(probit2)\n\n\nCall:\nglm(formula = y1 ~ p_ratio + a1 + a2, family = binomial(link = probit), \n    data = choice_df)\n\nCoefficients:\n            Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept) -0.54634    0.07756  -7.044 1.87e-12 ***\np_ratio     -0.22180    0.01524 -14.559  &lt; 2e-16 ***\na1           0.66314    0.09162   7.238 4.55e-13 ***\na2          -0.32291    0.09884  -3.267  0.00109 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 1384.5  on 999  degrees of freedom\nResidual deviance: 1066.9  on 996  degrees of freedom\nAIC: 1074.9\n\nNumber of Fisher Scoring iterations: 4\n\n# コード8-11\nDescTools::PseudoR2(probit2)\n\nMcFadden \n0.229384 \n\n# コード8-12\nprobit2_ame &lt;- probitmfx(y1 ~ p_ratio + a1 + a2,\n    data = choice_df, atmean = FALSE\n)\nprobit2_ame\n\nCall:\nprobitmfx(formula = y1 ~ p_ratio + a1 + a2, data = choice_df, \n    atmean = FALSE)\n\nMarginal Effects:\n             dF/dx  Std. Err.        z     P&gt;|z|    \np_ratio -0.0669199  0.0029405 -22.7581 &lt; 2.2e-16 ***\na1       0.2036848  0.0270475   7.5306 5.049e-14 ***\na2      -0.0969891  0.0291848  -3.3233 0.0008897 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\ndF/dx is for discrete change for the following variables:\n\n[1] \"a1\" \"a2\"\n\n\n\n# コード8-13\ndata(Cracker, package = \"mlogit\")\nhead(Cracker, n = 20)\n\n\n  \n\n\n# コード8-14\ncracker &lt;- mlogit.data(Cracker,\n    choice = \"choice\", shape = \"wide\",\n    varying = c(2:13)\n)\nhead(cracker, n = 20)\n\n~~~~~~~\n first 20 observations out of 13168 \n~~~~~~~\n   id choice      alt disp feat price chid    idx\n1   1  FALSE  keebler    0    0    88    1 1:bler\n2   1   TRUE  nabisco    0    0   120    1 1:isco\n3   1  FALSE  private    0    0    71    1 1:vate\n4   1  FALSE sunshine    0    0    98    1 1:hine\n5   1  FALSE  keebler    0    0   109    2 2:bler\n6   1   TRUE  nabisco    0    0    99    2 2:isco\n7   1  FALSE  private    0    0    71    2 2:vate\n8   1  FALSE sunshine    0    0    99    2 2:hine\n9   1  FALSE  keebler    0    0   109    3 3:bler\n10  1  FALSE  nabisco    0    0   109    3 3:isco\n11  1  FALSE  private    0    0    78    3 3:vate\n12  1   TRUE sunshine    1    0    49    3 3:hine\n13  1  FALSE  keebler    0    0   109    4 4:bler\n14  1   TRUE  nabisco    0    0    89    4 4:isco\n15  1  FALSE  private    0    0    78    4 4:vate\n16  1  FALSE sunshine    0    0   103    4 4:hine\n17  1  FALSE  keebler    0    0   109    5 5:bler\n18  1   TRUE  nabisco    0    0   119    5 5:isco\n19  1  FALSE  private    0    0    64    5 5:vate\n20  1  FALSE sunshine    0    0   109    5 5:hine\n\n~~~ indexes ~~~~\n   chid      alt\n1     1  keebler\n2     1  nabisco\n3     1  private\n4     1 sunshine\n5     2  keebler\n6     2  nabisco\n7     2  private\n8     2 sunshine\n9     3  keebler\n10    3  nabisco\n11    3  private\n12    3 sunshine\n13    4  keebler\n14    4  nabisco\n15    4  private\n16    4 sunshine\n17    5  keebler\n18    5  nabisco\n19    5  private\n20    5 sunshine\nindexes:  1, 2 \n\n# コード8-15\nml_cracker &lt;- mlogit(choice ~ price | 1 | disp + feat,\n    probit = FALSE,\n    data = cracker\n)\n\nsummary(ml_cracker)\n\n\nCall:\nmlogit(formula = choice ~ price | 1 | disp + feat, data = cracker, \n    probit = FALSE, method = \"nr\")\n\nFrequencies of alternatives:choice\n keebler  nabisco  private sunshine \n0.068651 0.544350 0.314399 0.072600 \n\nnr method\n5 iterations, 0h:0m:0s \ng'(-H)^-1g = 0.000258 \nsuccessive function values within tolerance limits \n\nCoefficients :\n                       Estimate Std. Error  z-value  Pr(&gt;|z|)    \n(Intercept):nabisco   2.0011226  0.0831336  24.0712 &lt; 2.2e-16 ***\n(Intercept):private   0.3193793  0.1238052   2.5797 0.0098888 ** \n(Intercept):sunshine -0.5435987  0.1139407  -4.7709 1.834e-06 ***\nprice                -0.0300966  0.0021082 -14.2761 &lt; 2.2e-16 ***\ndisp:keebler          0.2999316  0.2070369   1.4487 0.1474251    \ndisp:nabisco          0.1011111  0.0773633   1.3070 0.1912249    \ndisp:private         -0.2244555  0.1495236  -1.5011 0.1333199    \ndisp:sunshine         0.4818670  0.1672400   2.8813 0.0039605 ** \nfeat:keebler          0.6678542  0.2581732   2.5868 0.0096859 ** \nfeat:nabisco          0.6047773  0.1404077   4.3073 1.653e-05 ***\nfeat:private          0.1726981  0.2004446   0.8616 0.3889213    \nfeat:sunshine         0.8304895  0.2340938   3.5477 0.0003886 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nLog-Likelihood: -3333.8\nMcFadden R^2:  0.052798 \nLikelihood ratio test : chisq = 371.66 (p.value = &lt; 2.22e-16)\n\n\n\n# コード8-16\n# パラメータの推定値（beta）の抽出\nbeta &lt;- probit2$coefficients\n\n# パラメータbeta と説明変数の線形結合を作成（beta_0 は定数項なので1 をかける）\nest_probit2 &lt;- cbind(\n    1, choice_df$p_ratio, choice_df$a1,\n    choice_df$a2\n) %*% beta\n\n# pnorm によって標準正規分布の分布関数による計算を実行する。\n# 製品1(c1) を選ぶ確率の予測値\npred_probit_c1 &lt;- pnorm(est_probit2)\nmean(pred_probit_c1)\n\n[1] 0.4789384\n\n# コード8-17\n# ロジットモデルの場合\nlogit2 &lt;- glm(y1 ~ p_ratio + a1 + a2,\n    family = binomial(link = logit),\n    data = choice_df\n)\nbeta_logit &lt;- logit2$coefficients\nest_logit2 &lt;- cbind(\n    1, choice_df$p_ratio, choice_df$a1,\n    choice_df$a2\n) %*% beta_logit\npred_logit_c1 &lt;- (exp(est_logit2)) / (1 + exp(est_logit2))\nmean(pred_logit_c1)\n\n[1] 0.479\n\n# コード8-18\nchoice_df_v &lt;- choice_df %&gt;%\n    mutate(\n        p1_v = p1 - 1,\n        p_ratio_v = p1_v - p2\n    )\nest_probit_v &lt;- cbind(\n    1, choice_df_v$p_ratio_v, choice_df_v$a1,\n    choice_df_v$a2\n) %*% beta\n\n# pnorm によって標準正規分布の分布関数による計算を実行する。\n# 製品1(c1) を選ぶ確率の予測値\npred_probit_v &lt;- pnorm(est_probit_v)\nmean(pred_probit_v)\n\n[1] 0.5459071",
    "crumbs": [
      "第2部 仮説検証型データ分析",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>第8章 消費者の選択と離散選択モデル</span>"
    ]
  }
]